# Real-Time Fraud Detection Data Lakehouse

Há»‡ thá»‘ng Data Lakehouse phÃ¡t hiá»‡n gian láº­n tháº» tÃ­n dá»¥ng trong thá»i gian thá»±c sá»­ dá»¥ng **Sparkov Credit Card Transactions Dataset** vá»›i kiáº¿n trÃºc Medallion (Bronze-Silver-Gold).

![Architecture Diagram](docs/architecture.png)

## Tá»•ng quan

Dá»± Ã¡n xÃ¢y dá»±ng pipeline xá»­ lÃ½ dá»¯ liá»‡u end-to-end:

1. **Thu tháº­p dá»¯ liá»‡u**: PostgreSQL â†’ Debezium CDC â†’ Kafka (real-time streaming)
2. **Xá»­ lÃ½ dá»¯ liá»‡u**: Apache Spark vá»›i Delta Lake (Bronze/Silver/Gold layers)
3. **Feature Engineering**: 15 features tá»« dá»¯ liá»‡u Ä‘á»‹a lÃ½, nhÃ¢n kháº©u há»c, giao dá»‹ch
4. **Machine Learning**: Random Forest & Logistic Regression (99%+ accuracy)
5. **Model Serving**: FastAPI cho prediction real-time

## Tech Stack

| Component         | Technology               | MÃ´ táº£                          |
| ----------------- | ------------------------ | ------------------------------ |
| **Source DB**     | PostgreSQL 14            | OLTP database vá»›i CDC enabled  |
| **CDC**           | Debezium 2.5             | Change Data Capture connector  |
| **Streaming**     | Apache Kafka             | Message broker                 |
| **Processing**    | Apache Spark 3.4.1       | Stream & batch processing      |
| **Storage**       | Delta Lake 2.4.0 + MinIO | ACID transactions, time travel |
| **Metastore**     | Hive Metastore           | Table metadata management      |
| **ML**            | Scikit-learn, MLflow     | Model training & registry      |
| **API**           | FastAPI                  | Real-time prediction service   |
| **Orchestration** | Apache Airflow           | Workflow scheduling            |

## Cáº¥u trÃºc thÆ° má»¥c

```
real-time-fraud-detection-lakehouse/
â”œâ”€â”€ airflow/dags/              # Airflow DAGs (model retraining, reports)
â”œâ”€â”€ config/                    # Service configurations
â”‚   â”œâ”€â”€ metastore/             # Hive metastore config
â”‚   â”œâ”€â”€ spark/                 # Spark defaults
â”‚   â””â”€â”€ trino/                 # Trino settings
â”œâ”€â”€ data/                      # Sparkov dataset (CSV files)
â”œâ”€â”€ database/                  # PostgreSQL initialization
â”‚   â””â”€â”€ init_postgres.sql      # Schema setup (22 columns)
â”œâ”€â”€ deployment/                # Infrastructure automation
â”‚   â”œâ”€â”€ debezium/              # CDC configuration scripts
â”‚   â””â”€â”€ minio/                 # MinIO bucket setup
â”œâ”€â”€ docs/                      # Documentation
â”‚   â””â”€â”€ PROJECT_SPECIFICATION.md
â”œâ”€â”€ notebooks/                 # Jupyter notebooks (EDA, experiments)
â”œâ”€â”€ services/                  # Microservices
â”‚   â”œâ”€â”€ data-producer/         # PostgreSQL data simulator
â”‚   â”œâ”€â”€ fraud-detection-api/   # FastAPI prediction service
â”‚   â””â”€â”€ mlflow/                # MLflow tracking server
â”œâ”€â”€ spark/                     # Custom Spark with ML libraries
â”‚   â”œâ”€â”€ app/                   # PySpark jobs
â”‚   â”‚   â”œâ”€â”€ streaming_job.py   # Bronze: Kafka CDC â†’ Delta Lake (continuous)
â”‚   â”‚   â”œâ”€â”€ silver_job.py      # Silver: Feature engineering (batch every 5 min)
â”‚   â”‚   â”œâ”€â”€ gold_job.py        # Gold: Star Schema (batch every 5 min)
â”‚   â”‚   â”œâ”€â”€ ml_training_job.py # Model training pipeline
â”‚   â”‚   â”œâ”€â”€ run_silver.sh      # Shell wrapper for silver batch
â”‚   â”‚   â””â”€â”€ run_gold.sh        # Shell wrapper for gold batch
â”‚   â””â”€â”€ Dockerfile             # Spark + MLflow + ML libraries
â”œâ”€â”€ sql/                       # SQL views for Gold layer
â”‚   â””â”€â”€ gold_layer_views.sql   # Materialized views for dashboards
â”œâ”€â”€ docker-compose.yml         # 11 services orchestration
â””â”€â”€ README.md
```

## Dataset

**Sparkov Credit Card Transactions Fraud Detection Dataset** ([Kaggle](https://www.kaggle.com/datasets/kartik2112/fraud-detection))

- `data/fraudTrain.csv` - 1,296,675 transactions (01/2019 - 12/2020)
- `data/fraudTest.csv` - 555,719 transactions
- **22 columns**: Geographic (lat/long), demographic (age, gender, job), transaction (amount, merchant, category)

### Schema chÃ­nh

| Column                    | Type     | Description                  |
| ------------------------- | -------- | ---------------------------- |
| `trans_date_trans_time`   | DateTime | Thá»i gian giao dá»‹ch          |
| `cc_num`                  | Long     | Sá»‘ tháº» tÃ­n dá»¥ng              |
| `merchant`                | String   | TÃªn cá»­a hÃ ng                 |
| `category`                | String   | Danh má»¥c (grocery, gas, ...) |
| `amt`                     | Double   | Sá»‘ tiá»n giao dá»‹ch            |
| `gender`                  | String   | Giá»›i tÃ­nh (M/F)              |
| `lat`, `long`             | Double   | Vá»‹ trÃ­ khÃ¡ch hÃ ng            |
| `merch_lat`, `merch_long` | Double   | Vá»‹ trÃ­ cá»­a hÃ ng              |
| `is_fraud`                | Integer  | NhÃ£n gian láº­n (0/1)          |

### Feature Engineering (40 features)

**Geographic** (2): `distance_km` (Haversine), `is_distant_transaction`  
**Demographic** (2): `age`, `gender_encoded`  
**Time** (6): `hour`, `day_of_week`, `is_weekend`, `is_late_night`, `hour_sin`, `hour_cos`  
**Amount** (4): `log_amount`, `amount_bin`, `is_zero_amount`, `is_high_amount`  
**Original** (26): All columns from Bronze layer preserved

## Kiáº¿n trÃºc há»‡ thá»‘ng

### Medallion Architecture (Hybrid: Streaming + Batch)

Há»‡ thá»‘ng sá»­ dá»¥ng **kiáº¿n trÃºc lai** Ä‘á»ƒ tá»‘i Æ°u CPU vÃ  latency:

```
PostgreSQL (Source)
    â†“ Debezium CDC
Kafka (postgres.public.transactions)
    â†“ Bronze Streaming (Continuous, ~195% CPU)
Bronze Delta Lake (s3a://lakehouse/bronze/)
    â†“ Silver Batch (Every 5 minutes, 0% CPU during sleep)
Silver Delta Lake (s3a://lakehouse/silver/)
    â†“ Gold Batch (Every 5 minutes, 0% CPU during sleep)
Gold Delta Lake (s3a://lakehouse/gold/) - 5 tables
    â†“ Trino Delta Catalog (Direct access, no Hive Metastore)
Query Layer (Trino + Metabase)
```

**Lá»£i Ã­ch:**
- âœ… **Bronze Layer**: Real-time CDC capture tá»« Kafka (streaming liÃªn tá»¥c)
- âœ… **Silver Layer**: Feature engineering má»—i 5 phÃºt (batch) - giáº£m 60% CPU
- âœ… **Gold Layer**: Star schema má»—i 5 phÃºt (batch) - data sáºµn sÃ ng cho analytics
- âœ… **Latency**: 5-10 phÃºt tá»« source Ä‘áº¿n Gold (cháº¥p nháº­n Ä‘Æ°á»£c cho fraud detection analytics)
- âœ… **Resource**: Bronze ~195% CPU, Silver/Gold 0% CPU khi sleep

### Delta Lake Integration

**KhÃ´ng sá»­ dá»¥ng Hive Metastore** - Delta Lake tá»± quáº£n lÃ½ metadata qua `_delta_log/`:
- âœ… ACID transactions
- âœ… Time travel (Delta Lake history)
- âœ… Schema evolution vá»›i `overwriteSchema=true`
- âœ… Trino query trá»±c tiáº¿p qua Delta catalog

## HÆ°á»›ng dáº«n cháº¡y

### 1. YÃªu cáº§u há»‡ thá»‘ng

- Docker & Docker Compose
- Python 3.9+
- 8GB RAM, 20GB disk space

---

### 2. Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng

```bash
# Clone repository
git clone https://github.com/bin-bard/real-time-fraud-detection-lakehouse.git
cd real-time-fraud-detection-lakehouse

# Khá»Ÿi Ä‘á»™ng toÃ n bá»™ há»‡ thá»‘ng
docker-compose up -d
```

> **LÆ°u Ã½:** Táº¥t cáº£ services tá»± Ä‘á»™ng start, bao gá»“m Bronze streaming vÃ  Silver/Gold batch jobs.

---

### 3. Kiá»ƒm tra Data Pipeline

Pipeline tá»± Ä‘á»™ng cháº¡y vá»›i **3 Spark jobs**:

#### Kiá»ƒm tra logs

```bash
# Xem táº¥t cáº£ 3 jobs
docker-compose logs -f bronze-streaming silver-job gold-job

# Hoáº·c tá»«ng job riÃªng láº»
docker logs -f bronze-streaming    # Bronze: CDC â†’ Delta Lake
docker logs -f silver-job          # Silver: Feature engineering (every 5 min)
docker logs -f gold-job            # Gold: Star schema (every 5 min)
```

#### Verify thÃ nh cÃ´ng

**Bronze streaming** (continuous):
```
Writing batch 100 to Bronze layer...
Batch 100 written to Bronze successfully.
```

**Silver batch** (every 5 minutes):
```
ğŸ¥ˆ Starting Bronze to Silver layer BATCH processing...
Found 86427 new records to process
âœ… Successfully processed 86427 records to Silver layer!
âœ… Silver batch completed. Sleeping 5 minutes...
```

**Gold batch** (every 5 minutes):
```
âœ¨ Gold layer batch processing completed!
ğŸ“Š Processed 86527 records from Silver layer
ğŸ“Š Updated tables:
   - dim_customer -> s3a://lakehouse/gold/dim_customer
   - dim_merchant -> s3a://lakehouse/gold/dim_merchant
   - dim_time -> s3a://lakehouse/gold/dim_time
   - dim_location -> s3a://lakehouse/gold/dim_location
   - fact_transactions -> s3a://lakehouse/gold/fact_transactions
```

#### Kiá»ƒm tra CPU usage

```bash
docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}" | grep -E "bronze|silver|gold"
```

**Output mong Ä‘á»£i:**
```
bronze-streaming   195.96%   935.5MiB / 7.76GiB
silver-job         0.00%     219.5MiB / 7.76GiB
gold-job           0.00%     2.555MiB / 7.76GiB
```

âœ… **Bronze**: ~195% CPU (streaming liÃªn tá»¥c)  
âœ… **Silver**: 0% CPU (Ä‘ang sleep 5 phÃºt)  
âœ… **Gold**: 0% CPU (Ä‘ang sleep 5 phÃºt)

---

### 4. Cáº¥u trÃºc Spark Jobs

#### Bronze Layer (`streaming_job.py`)
- **Mode**: Structured Streaming (continuous)
- **Input**: Kafka topic `postgres.public.transactions`
- **Processing**: Parse Debezium CDC format (`$.after.*`)
- **Output**: Delta Lake `s3a://lakehouse/bronze/transactions`
- **Partitioning**: By `year`, `month`, `day`

#### Silver Layer (`silver_job.py`)
- **Mode**: Batch (every 5 minutes)
- **Input**: Bronze Delta Lake
- **Processing**: 
  - Data quality checks
  - Type casting (String â†’ Double/Long/Date)
  - Feature engineering (40 features)
  - Incremental processing (only new data)
- **Output**: Delta Lake `s3a://lakehouse/silver/transactions`
- **Config**: Ancient date support (`datetimeRebaseModeInWrite=LEGACY`)

#### Gold Layer (`gold_job.py`)
- **Mode**: Batch (every 5 minutes)
- **Input**: Silver Delta Lake
- **Processing**: 
  - Star schema transformation
  - Hash-based surrogate keys
  - Incremental processing
- **Output**: 5 Delta tables
  - `dim_customer`: Customer dimension (cc_num, first, last, gender, dob, etc.)
  - `dim_merchant`: Merchant dimension (merchant, category, merch_lat, merch_long)
  - `dim_time`: Time dimension (date, hour, day_of_week, is_weekend)
  - `dim_location`: Location dimension (city, state, zip, lat, long)
  - `fact_transactions`: Fact table (foreign keys + measures)
  - `dim_merchant` - Dimension table (cá»­a hÃ ng)
  - `dim_time` - Dimension table (thá»i gian)
  - `dim_location` - Dimension table (Ä‘á»‹a Ä‘iá»ƒm)
  - `fact_transactions` - Fact table (giao dá»‹ch vá»›i metrics)
- Checkpoint Ä‘Æ°á»£c lÆ°u táº¡i `s3a://lakehouse/checkpoints/silver_to_gold/*`
- Trigger má»—i 30 giÃ¢y Ä‘á»ƒ xá»­ lÃ½ micro-batch
- **KhÃ´ng táº¯t terminal nÃ y** - Ä‘á»ƒ job cháº¡y liÃªn tá»¥c

---

**Luá»“ng xá»­ lÃ½ hoÃ n chá»‰nh (End-to-End):**

```
PostgreSQL INSERT â†’ Debezium CDC â†’ Kafka 
  â†“ (Bronze Streaming - Auto)
Bronze Layer (Delta Lake)
  â†“ (Silver Streaming - 30s trigger)
Silver Layer + Feature Engineering (15 features)
  â†“ (Gold Streaming - 30s trigger)
Gold Layer (Star Schema: 4 Dims + 1 Fact)
```

**Æ¯u Ä‘iá»ƒm kiáº¿n trÃºc streaming:**
- âœ… **Near Real-time**: Äá»™ trá»… ~30-60 giÃ¢y tá»« INSERT Ä‘áº¿n Gold
- âœ… **Tá»± Ä‘á»™ng**: KhÃ´ng cáº§n trigger thá»§ cÃ´ng
- âœ… **Scalable**: Xá»­ lÃ½ Ä‘Æ°á»£c millions records/day
- âœ… **Fault-tolerant**: Checkpoint Ä‘áº£m báº£o exactly-once processing

---

### 5. Query Data vá»›i Trino

Trino cÃ³ thá»ƒ query trá»±c tiáº¿p Delta Lake tables **khÃ´ng cáº§n Hive Metastore**:

```sql
-- Truy cáº­p Trino CLI
docker exec -it trino trino

-- List catalogs
SHOW CATALOGS;

-- Query Bronze layer
SELECT COUNT(*) FROM delta.default."s3a://lakehouse/bronze/transactions";

-- Query Silver layer (vá»›i features)
SELECT trans_num, amt, distance_km, age, is_fraud 
FROM delta.default."s3a://lakehouse/silver/transactions"
LIMIT 10;

-- Query Gold layer - Star Schema
SELECT 
  f.transaction_amount,
  c.first_name || ' ' || c.last_name AS customer_name,
  m.merchant_name,
  t.hour,
  l.state
FROM delta.default."s3a://lakehouse/gold/fact_transactions" f
JOIN delta.default."s3a://lakehouse/gold/dim_customer" c ON f.customer_key = c.customer_key
JOIN delta.default."s3a://lakehouse/gold/dim_merchant" m ON f.merchant_key = m.merchant_key
JOIN delta.default."s3a://lakehouse/gold/dim_time" t ON f.time_key = t.time_key
JOIN delta.default."s3a://lakehouse/gold/dim_location" l ON f.location_key = l.location_key
WHERE f.is_fraud = 1
LIMIT 20;
```

---

### 6. Truy cáº­p Services

| Service             | URL                   | Username / Password                             | Ghi chÃº                                           |
| ------------------- | --------------------- | ----------------------------------------------- | ------------------------------------------------- |
| Spark Master UI     | http://localhost:8080 | KhÃ´ng cáº§n                                       | Monitoring Spark jobs                             |
| MinIO Console       | http://localhost:9001 | `minio` / `minio123`                            | Quáº£n lÃ½ buckets vÃ  files (Data Lake)              |
| MLflow UI           | http://localhost:5000 | KhÃ´ng cáº§n                                       | ML model tracking & registry                      |
| Kafka UI            | http://localhost:9002 | KhÃ´ng cáº§n                                       | Xem topics, messages, consumer groups             |
| Trino UI            | http://localhost:8085 | KhÃ´ng cáº§n                                       | Query engine monitoring                           |
| Metabase            | http://localhost:3000 | TÃ¹y chá»n (vÃ­ dá»¥:`admin@admin.com` / `admin123`) | BI Dashboard, tá»± táº¡o tÃ i khoáº£n admin láº§n Ä‘áº§u      |
| Fraud Detection API | http://localhost:8000 | KhÃ´ng cáº§n                                       | Real-time prediction endpoint                     |
| Kafka Broker        | localhost:9092        | KhÃ´ng cáº§n                                       | Kafka bootstrap server                            |
| PostgreSQL (Source) | localhost:5432        | `postgres` / `postgres`                         | Database `frauddb`                                |
| Metabase DB         | Internal              | `postgres` / `postgres`                         | Database `metabase` (khÃ´ng cáº§n truy cáº­p thá»§ cÃ´ng) |
| Hive Metastore DB   | Internal (9083)       | `hive` / `hive`                                 | Postgres cho Hive (khÃ´ng expose ra ngoÃ i)         |

> **LÆ°u Ã½ quan trá»ng:**
>
> - **MinIO, PostgreSQL:** Credentials cá»‘ Ä‘á»‹nh trong `docker-compose.yml` (cÃ³ thá»ƒ Ä‘á»•i trÆ°á»›c khi khá»Ÿi Ä‘á»™ng).
> - **Metabase:** Táº¡o tÃ i khoáº£n admin khi truy cáº­p láº§n Ä‘áº§u, email/password tÃ¹y chá»n (vÃ­ dá»¥: `admin@admin.com` / `admin123`).
> - **Spark UI, Kafka UI, Trino UI:** KhÃ´ng yÃªu cáº§u Ä‘Äƒng nháº­p.
> - **Airflow, MLflow:** ChÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng trong docker-compose hiá»‡n táº¡i (cÃ³ thá»ƒ thÃªm sau).

### 5. Kiá»ƒm tra Pipeline

**Check Bronze layer data:**

```bash
# MinIO console: http://localhost:9001
# Navigate to: lakehouse/bronze/transactions/
```

**Check Kafka messages:**

```bash
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic postgres.public.transactions \
  --from-beginning --max-messages 5
```

### XÃ¡c minh CDC (INSERT/UPDATE/DELETE) vÃ  giÃ¡ trá»‹ trÆ°á»ng `amt`

**1. Láº¥y trans_num thá»±c táº¿ Ä‘á»ƒ test:**

```sql
SELECT trans_num FROM transactions LIMIT 5;
```

**2. Thá»±c hiá»‡n cÃ¡c thao tÃ¡c trÃªn PostgreSQL:**

```sql
-- UPDATE
UPDATE transactions SET amt = amt + 1 WHERE trans_num = '<trans_num thá»±c táº¿>';
-- DELETE
DELETE FROM transactions WHERE trans_num = '<trans_num thá»±c táº¿>';
```

**3. Kiá»ƒm tra message CDC trÃªn Kafka:**

```bash
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic postgres.public.transactions --from-beginning --max-messages 100000 --timeout-ms 3000 2>$null | Select-String -Pattern "<trans_num thá»±c táº¿>"
```

Káº¿t quáº£:

- `"op":"c"` = insert, `"op":"u"` = update, `"op":"d"` = delete.
- TrÆ°á»ng `amt` sáº½ á»Ÿ dáº¡ng mÃ£ hÃ³a Base64 (vÃ­ dá»¥: "amt":"Ark=").

**4. Decode giÃ¡ trá»‹ amt (PowerShell):**

```powershell
[System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String("Ark="))
```

Viá»‡c decode nÃ y chá»‰ Ä‘á»ƒ xem giÃ¡ trá»‹ thá»±c, khÃ´ng áº£nh hÆ°á»Ÿng pipeline.

**5. Xem Kafka messages qua UI:**

Truy cáº­p Kafka UI táº¡i http://localhost:9002 Ä‘á»ƒ xem topics, messages, consumer groups qua giao diá»‡n web thÃ¢n thiá»‡n.

**Monitor Spark jobs:**

---

### 7. Troubleshooting & Maintenance

#### Reset toÃ n bá»™ há»‡ thá»‘ng

```bash
docker-compose down -v
docker-compose up -d --build
```

#### Check logs khi cÃ³ lá»—i

```bash
# Check Bronze streaming
docker logs bronze-streaming --tail 50

# Check Silver batch
docker logs silver-job --tail 50

# Check Gold batch  
docker logs gold-job --tail 50

# Check Spark Master
docker logs spark-master
```

#### Common issues

**High CPU usage**:
- Bronze streaming: ~195% CPU (bÃ¬nh thÆ°á»ng)
- Silver/Gold batch: 0% CPU khi sleep, spike khi cháº¡y (bÃ¬nh thÆ°á»ng)
- Náº¿u cáº£ 3 jobs Ä‘á»u >200% CPU: Xem xÃ©t giáº£m batch size hoáº·c tÄƒng sleep interval

**Job fails to start**:
- Check Spark Master UI: http://localhost:8080
- Verify MinIO accessible: http://localhost:9001
- Check Kafka messages: `docker logs kafka`

---

### 8. Lakehouse Structure

```
s3a://lakehouse/
â”œâ”€â”€ bronze/transactions/          # Raw CDC data (Debezium format parsed)
â”‚   â””â”€â”€ _delta_log/              # Delta Lake transaction logs
â”œâ”€â”€ silver/transactions/          # 40 engineered features
â”‚   â””â”€â”€ _delta_log/
â”œâ”€â”€ gold/                         # Star Schema (5 tables)
â”‚   â”œâ”€â”€ dim_customer/
â”‚   â”œâ”€â”€ dim_merchant/
â”‚   â”œâ”€â”€ dim_time/
â”‚   â”œâ”€â”€ dim_location/
â”‚   â””â”€â”€ fact_transactions/
â”œâ”€â”€ checkpoints/                  # Spark streaming checkpoints
â”‚   â”œâ”€â”€ kafka_to_bronze/         # Bronze streaming state
â”‚   â”œâ”€â”€ bronze_to_silver_batch/  # Silver batch watermark
â”‚   â””â”€â”€ silver_to_gold_batch/    # Gold batch watermark
â””â”€â”€ models/                       # ML models & artifacts (future)
```

---

### 9. Kiáº¿n trÃºc Data Flow

**Luá»“ng xá»­ lÃ½ hoÃ n chá»‰nh:**

```
PostgreSQL INSERT
    â†“ Debezium CDC (Change Data Capture)
Kafka Topic: postgres.public.transactions
    â†“ Bronze Streaming (Continuous, ~195% CPU)
Bronze Delta Lake (s3a://lakehouse/bronze/)
    â†“ Silver Batch (Every 5 minutes, spike to ~100% CPU then sleep)
Silver Delta Lake (40 features, s3a://lakehouse/silver/)
    â†“ Gold Batch (Every 5 minutes, spike to ~100% CPU then sleep)
Gold Delta Lake (5 tables, s3a://lakehouse/gold/)
    â†“ Trino Delta Catalog (Direct query, no Hive Metastore)
Metabase Dashboard / Analytics
```

**Latency:**
- Bronze: Real-time (~1-2 seconds from PostgreSQL INSERT)
- Silver: 5-10 minutes (batch interval + processing time)
- Gold: 10-15 minutes (waits for Silver + processing time)

**Resource Usage:**
- Bronze: 195% CPU (continuous streaming)
- Silver: 0% CPU (95% of time), spike when processing
- Gold: 0% CPU (95% of time), spike when processing
- **Total**: ~195-400% CPU (depending on batch cycle)

---

### 10. Services Container Map

| Service             | URL                   | Credentials             | Purpose                                  |
| ------------------- | --------------------- | ----------------------- | ---------------------------------------- |
| Spark Master UI     | http://localhost:8080 | None                    | Monitor Spark jobs & resource allocation |
| MinIO Console       | http://localhost:9001 | minio / minio123        | S3-compatible Data Lake storage          |
| MLflow UI           | http://localhost:5000 | None                    | ML model tracking & registry             |
| Kafka UI            | http://localhost:9002 | None                    | Kafka topics & messages monitoring       |
| Trino UI            | http://localhost:8085 | None                    | Distributed SQL query engine             |
| Metabase            | http://localhost:3000 | admin@admin.com / admin | BI Dashboard & visualization             |
| Fraud Detection API | http://localhost:8000 | None                    | Real-time prediction endpoint (future)   |
| Kafka Broker        | localhost:9092        | None                    | Message streaming platform               |
| PostgreSQL          | localhost:5432        | postgres / postgres     | Source database (frauddb)                |

---

### 11. Key Features & Achievements

âœ… **Hybrid Architecture**: Streaming (Bronze) + Batch (Silver/Gold) for optimal CPU usage  
âœ… **Real-time CDC**: Debezium captures INSERT/UPDATE/DELETE from PostgreSQL  
âœ… **ACID Transactions**: Delta Lake ensures data consistency  
âœ… **Incremental Processing**: Only process new data (watermark-based)  
âœ… **Schema Evolution**: Support for ancient dates with LEGACY mode  
âœ… **40 Features**: Geographic, demographic, time-based, amount-based  
âœ… **Star Schema**: 4 dimensions + 1 fact table for analytics  
âœ… **Direct Trino Query**: No Hive Metastore dependency  
âœ… **60% CPU Reduction**: From 300%+ to ~195% by moving to batch processing  

---

## Chi tiáº¿t ká»¹ thuáº­t

Xem file `docs/PROJECT_SPECIFICATION.md` Ä‘á»ƒ hiá»ƒu rÃµ:

- Kiáº¿n trÃºc há»‡ thá»‘ng chi tiáº¿t
- YÃªu cáº§u nghiá»‡p vá»¥
- Data flow vÃ  processing layers
- ML pipeline specifications
