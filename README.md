# Real-Time Fraud Detection Lakehouse

H·ªá th·ªëng Data Lakehouse ph√°t hi·ªán gian l·∫≠n th·∫ª t√≠n d·ª•ng theo th·ªùi gian th·ª±c s·ª≠ d·ª•ng **Delta Lake** + **Apache Spark** + **Trino**.

## üéØ T·ªïng quan

D·ª± √°n x√¢y d·ª±ng pipeline x·ª≠ l√Ω d·ªØ li·ªáu end-to-end t·ª´ CDC (Change Data Capture) ƒë·∫øn Analytics Dashboard:

- **Real-time CDC**: PostgreSQL ‚Üí Debezium ‚Üí Kafka ‚Üí Bronze (Streaming)
- **Batch ETL**: Bronze ‚Üí Silver ‚Üí Gold (Airflow m·ªói 5 ph√∫t)
- **ML Training**: RandomForest + LogisticRegression (Airflow h√†ng ng√†y 2 AM)
- **Analytics**: Trino + Metabase Dashboard

## üõ†Ô∏è Tech Stack

| Component         | Technology           | Port       | M√¥ t·∫£                           |
| ----------------- | -------------------- | ---------- | ------------------------------- |
| **Source DB**     | PostgreSQL 14        | 5432       | OLTP database v·ªõi CDC enabled   |
| **CDC**           | Debezium 2.5         | 8083       | Change Data Capture             |
| **Streaming**     | Apache Kafka         | 9092       | Message broker                  |
| **Processing**    | Spark 3.4.1          | 8080       | Stream & batch processing       |
| **Storage**       | Delta Lake + MinIO   | 9000, 9001 | ACID lakehouse                  |
| **Metastore**     | Hive Metastore 3.1.3 | 9083       | Metadata cache (optional)       |
| **Query**         | Trino                | 8085       | Distributed SQL engine          |
| **Orchestration** | Airflow 2.8.0        | 8081       | Workflow scheduling             |
| **ML Tracking**   | MLflow 2.8.0         | 5000       | Model tracking                  |
| **Visualization** | Metabase             | 3000       | BI dashboard                    |
| **API**           | FastAPI              | 8000       | Real-time prediction (optional) |

## üìã Y√™u c·∫ßu h·ªá th·ªëng

**Ph·∫ßn c·ª©ng:**

- CPU: 6 cores minimum (khuy·∫øn ngh·ªã 8+)
- RAM: 10GB minimum (khuy·∫øn ngh·ªã 16GB)
- Disk: 30GB free space

**Ph·∫ßn m·ªÅm:**

- Docker Desktop 4.0+ (Windows/Mac) ho·∫∑c Docker Engine 20.10+ (Linux)
- Docker Compose 2.0+
- PowerShell 5.1+ (Windows) ho·∫∑c Bash (Linux/Mac)

**C·∫•u h√¨nh Docker (Windows WSL2):**

T·∫°o file `C:\Users\<YourUsername>\.wslconfig`:

```ini
[wsl2]
memory=10GB
processors=6
swap=4GB
```

Sau ƒë√≥ restart WSL2:

```powershell
wsl --shutdown
```

## üöÄ H∆∞·ªõng d·∫´n ch·∫°y

### 1. Clone repository

```bash
git clone https://github.com/bin-bard/real-time-fraud-detection-lakehouse.git
cd real-time-fraud-detection-lakehouse
```

### 2. Kh·ªüi ƒë·ªông h·ªá th·ªëng

```bash
docker compose up -d --build
```

**‚è≥ Th·ªùi gian kh·ªüi ƒë·ªông:** ~5-10 ph√∫t (t·∫£i images + kh·ªüi t·∫°o services)

### 3. Bulk load initial data (Optional - Khuy·∫øn ngh·ªã)

ƒê·ªÉ c√≥ ƒë·ªß data cho ML training ngay l·∫≠p t·ª©c:

```bash
# Load 50K transactions (~250 fraud samples)
docker exec data-producer python producer.py --bulk-load 50000
```

**K·∫øt qu·∫£:**

- ~50K records trong 2-3 ph√∫t
- ~250 fraud transactions (0.5% fraud rate)
- ƒê·ªß data cho ML training ngay
- Producer t·ª± ƒë·ªông ti·∫øp t·ª•c streaming sau khi xong

**Checkpoint safe:** Kh√¥ng duplicate records, resume ƒë√∫ng v·ªã tr√≠ sau khi restart.

### 4. Verify h·ªá th·ªëng

#### Check services ƒëang ch·∫°y

```bash
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
```

**Mong ƒë·ª£i:** 15+ containers v·ªõi status `Up`

#### Check Bronze streaming

```bash
docker logs bronze-streaming --tail 20
```

**Mong ƒë·ª£i:**

```
Batch 5 processing started
Writing 142 records to Bronze layer...
‚úÖ Batch 5 written successfully
```

#### Check Airflow DAG

- Truy c·∫≠p: http://localhost:8081 (`admin` / `admin`)
- DAG: `lakehouse_pipeline_taskflow` (m·ªói 5 ph√∫t)
- Verify: Silver/Gold tasks th√†nh c√¥ng

#### Check data trong MinIO

- Truy c·∫≠p: http://localhost:9001 (`minio` / `minio123`)
- Bucket: `lakehouse`
- Verify folders: `bronze/`, `silver/`, `gold/`

#### Query data qua Trino

```bash
docker exec -it trino trino --server localhost:8081
```

```sql
-- Verify data t·ªìn t·∫°i
SELECT COUNT(*) FROM delta.bronze.transactions;
SELECT COUNT(*) FROM delta.silver.transactions;
SELECT COUNT(*) FROM delta.gold.fact_transactions;

-- Sample data
SELECT * FROM delta.gold.fact_transactions LIMIT 5;

-- Fraud distribution
SELECT is_fraud, COUNT(*) as count
FROM delta.silver.transactions
GROUP BY is_fraud;

quit;
```

**‚ö†Ô∏è QUAN TR·ªåNG:** Query data ph·∫£i d√πng **`delta`** catalog (KH√îNG d√πng `hive`):

- ‚úÖ `delta.bronze.*`, `delta.silver.*`, `delta.gold.*`
- ‚ùå `hive.*` (ch·ªâ list tables, kh√¥ng query ƒë∆∞·ª£c Delta format)

## üîë Access Services

| Service             | URL                   | Username / Password | Ghi ch√∫                                    |
| ------------------- | --------------------- | ------------------- | ------------------------------------------ |
| **Airflow**         | http://localhost:8081 | `admin` / `admin`   | Workflow orchestration                     |
| **Spark Master UI** | http://localhost:8080 | -                   | Monitoring Spark jobs                      |
| **MinIO Console**   | http://localhost:9001 | `minio` / `minio123`| Data Lake storage                          |
| **MLflow UI**       | http://localhost:5000 | -                   | ML model tracking                          |
| **Kafka UI**        | http://localhost:9002 | -                   | Topics, messages, consumer groups          |
| **Trino UI**        | http://localhost:8085 | -                   | Query engine monitoring                    |
| **Metabase**        | http://localhost:3000 | (t·∫°o admin l·∫ßn ƒë·∫ßu) | BI Dashboard                               |
| **PostgreSQL**      | localhost:5432        | `postgres` / `postgres` | Source database                        |

## üìä Ki·∫øn tr√∫c h·ªá th·ªëng

### Medallion Architecture (Hybrid: Streaming + Batch)

```
PostgreSQL (Source)
    ‚Üì Debezium CDC
Kafka (postgres.public.transactions)
    ‚Üì Bronze Streaming (Continuous, ~195% CPU)
Bronze Delta Lake (s3a://lakehouse/bronze/)
    ‚Üì Silver Batch (Every 5 minutes via Airflow)
Silver Delta Lake (s3a://lakehouse/silver/)
    ‚Üì Gold Batch (Every 5 minutes via Airflow)
Gold Delta Lake (s3a://lakehouse/gold/) - 5 tables
    ‚Üì
Trino Delta Catalog (Query data)
    ‚Üì
Metabase/DBeaver (Analytics)
```

**L·ªõp d·ªØ li·ªáu:**

1. **Bronze** - Raw CDC data (real-time streaming)
2. **Silver** - Cleaned + Feature engineering (batch m·ªói 5 ph√∫t)
3. **Gold** - Star Schema: 4 dimensions + 1 fact table (batch m·ªói 5 ph√∫t)

**Gold Layer Tables:**

- `dim_customer` - Customer dimension
- `dim_merchant` - Merchant dimension
- `dim_time` - Time dimension
- `dim_location` - Location dimension
- `fact_transactions` - Transaction facts (25K+ records)

## ü§ñ ML Training

### Automated Training (Airflow)

- **Schedule:** Daily at 2 AM
- **DAG:** `model_retraining_taskflow`
- **Models:** RandomForest + LogisticRegression
- **Metrics:** Accuracy, Precision, Recall, F1, AUC

### Manual Trigger

Airflow UI ‚Üí `model_retraining_taskflow` ‚Üí ‚ñ∂Ô∏è Trigger DAG

### Resource Management

**Tr∆∞·ªõc khi ch·∫°y ML training:**

```powershell
# Gi·∫£i ph√≥ng ~2GB RAM + 1-2 CPU cores
.\scripts\prepare-ml-training.ps1
```

**Sau khi training xong:**

```powershell
# Kh√¥i ph·ª•c services
.\scripts\restore-services.ps1
```

### Verify models

- Truy c·∫≠p: http://localhost:5000
- Experiment: `fraud_detection_production`
- Check runs: RandomForest, LogisticRegression

### Training samples FAQ

**Q: T·∫°i sao ch·ªâ c√≥ ~15-20 training samples?**

**A:** ƒê√¢y l√† behavior ƒê√öNG v·ªõi real-world fraud detection!

| Metric                  | Value       | Explanation                |
| ----------------------- | ----------- | -------------------------- |
| Total records (Silver)  | ~4,200      | Sau v√†i ph√∫t streaming     |
| Fraud transactions      | ~10 (0.24%) | Real-world fraud rate 0.5% |
| After class balancing   | 10 + 10 = 20| Undersample majority 1:1   |
| Train/Test split (80/20)| 16 + 4      | Final dataset              |

**Gi·∫£i ph√°p:** Bulk load 50K records ‚Üí ~250 fraud samples ‚Üí better training

```bash
docker exec data-producer python producer.py --bulk-load 50000
```

## üîß K·∫øt n·ªëi Metabase

### Database Configuration

```yaml
Database Type: Trino
Display Name: Fraud Detection Lakehouse

Connection:
  Host: trino         # N·∫øu Metabase ch·∫°y trong Docker
  # Host: localhost   # N·∫øu Metabase ch·∫°y ngo√†i Docker
  Port: 8081          # Internal port (8085 for external)
  Catalog: delta      # ‚ö†Ô∏è IMPORTANT: D√πng delta, kh√¥ng ph·∫£i hive
  Database: gold      # Ho·∫∑c 'silver'/'bronze'

Authentication:
  Username: (leave empty)
  Password: (leave empty)
```

### Sample Queries

```sql
-- Fraud rate by category
SELECT
    transaction_category,
    COUNT(*) as total_transactions,
    SUM(CASE WHEN is_fraud = 1 THEN 1 ELSE 0 END) as fraud_count,
    ROUND(100.0 * SUM(CASE WHEN is_fraud = 1 THEN 1 ELSE 0 END) / COUNT(*), 2) as fraud_rate
FROM delta.gold.fact_transactions
GROUP BY transaction_category
ORDER BY fraud_rate DESC

-- Top 10 high-risk merchants
SELECT
    merchant_name,
    merchant_category,
    COUNT(*) as total_transactions,
    SUM(CASE WHEN is_fraud = 1 THEN 1 ELSE 0 END) as fraud_count
FROM delta.gold.fact_transactions
GROUP BY merchant_name, merchant_category
HAVING COUNT(*) > 10
ORDER BY fraud_count DESC
LIMIT 10
```

## üîß K·∫øt n·ªëi DBeaver/SQL Client

**JDBC URL:**

```
jdbc:trino://localhost:8085/delta
```

**Connection Settings:**

- Host: `localhost`
- Port: `8085`
- Database/Catalog: `delta`
- Schema: `gold` (ho·∫∑c `silver`, `bronze`)
- Username: `trino` (ho·∫∑c b·∫•t k·ª≥)
- Password: (ƒë·ªÉ tr·ªëng)

## üêõ Troubleshooting

### High CPU usage (>500%)

**B√¨nh th∆∞·ªùng:**

- `bronze-streaming`: ~195% CPU (continuous)
- `spark-master`: ~50-100% CPU khi ch·∫°y job
- `airflow-*`: ~10-30% CPU

**N·∫øu >600%:** Restart services

```bash
docker compose restart bronze-streaming spark-master spark-worker
```

### No data in Silver/Gold

```bash
# 1. Check Bronze c√≥ data
docker exec trino trino --server localhost:8081 --execute "SELECT COUNT(*) FROM delta.bronze.transactions"

# 2. Check Airflow DAG ƒëang ch·∫°y
# Airflow UI: http://localhost:8081 ‚Üí lakehouse_pipeline_taskflow

# 3. Check logs
docker logs airflow-scheduler --tail 50
```

### MLflow empty (no models)

```bash
# 1. Verify Silver c√≥ ƒë·ªß data (c·∫ßn √≠t nh·∫•t 1000 records v·ªõi fraud samples)
docker exec trino trino --server localhost:8081 --execute "SELECT is_fraud, COUNT(*) FROM delta.silver.transactions GROUP BY is_fraud"

# 2. Trigger training DAG
# Airflow UI ‚Üí model_retraining_taskflow ‚Üí Trigger DAG

# 3. Check logs
# Airflow UI ‚Üí model_retraining_taskflow ‚Üí train_ml_models ‚Üí Logs
```

### Reset to√†n b·ªô h·ªá th·ªëng

```bash
# ‚ö†Ô∏è C·∫£nh b√°o: X√≥a to√†n b·ªô data!
docker compose down -v
docker compose up -d --build
```

## üìñ Documentation

- **[PROJECT_SPECIFICATION.md](docs/PROJECT_SPECIFICATION.md)** - ƒê·∫∑c t·∫£ chi ti·∫øt architecture, data flow, requirements
- **[CHANGELOG.md](docs/CHANGELOG.md)** - L·ªãch s·ª≠ c·∫≠p nh·∫≠t, l·ªói ƒë√£ s·ª≠a, FAQ

## üìù License

MIT License - Nh√≥m 6, GVHD: ThS. Phan Th·ªã Th·ªÉ

## üë• Contributors

- Nguy·ªÖn Thanh T√†i - 22133049
- V√µ Tri·ªáu Ph√∫c - 22133043
