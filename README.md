# H·ªá th·ªëng Ph√°t hi·ªán Gian l·∫≠n Th·ªùi gian Th·ª±c - Data Lakehouse

H·ªá th·ªëng Data Lakehouse ph√°t hi·ªán gian l·∫≠n th·∫ª t√≠n d·ª•ng theo th·ªùi gian th·ª±c s·ª≠ d·ª•ng **Delta Lake** + **Apache Spark** + **Trino**.

![Ki·∫øn tr√∫c h·ªá th·ªëng](docs/architecture.png)

## üéØ T·ªïng quan

D·ª± √°n x√¢y d·ª±ng pipeline x·ª≠ l√Ω d·ªØ li·ªáu end-to-end t·ª´ CDC (Change Data Capture) ƒë·∫øn Dashboard ph√¢n t√≠ch:

- **CDC Th·ªùi gian th·ª±c**: PostgreSQL ‚Üí Debezium ‚Üí Kafka ‚Üí Bronze (Streaming)
- **ETL Batch**: Bronze ‚Üí Silver ‚Üí Gold (Airflow m·ªói 5 ph√∫t)
- **Hu·∫•n luy·ªán ML**: RandomForest + LogisticRegression (Airflow h√†ng ng√†y 2 gi·ªù s√°ng)
- **Ph√¢n t√≠ch**: Trino + Metabase Dashboard
- **Chatbot AI**: Streamlit + LangChain + Gemini (ti·∫øng Vi·ªát)

## üìö T√†i li·ªáu

- **[Setup Guide](docs/SETUP_GUIDE.md)** - H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t chi ti·∫øt cho ng∆∞·ªùi m·ªõi
- **[Chatbot Guide](docs/CHATBOT_GUIDE.md)** - H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng Fraud Chatbot
- **[Chatbot Architecture](docs/CHATBOT_ARCHITECTURE.md)** - Ki·∫øn tr√∫c modular c·ªßa chatbot
- **[Implementation Summary](docs/IMPLEMENTATION_SUMMARY.md)** - T·ªïng h·ª£p c√°c thay ƒë·ªïi
- **[Changelog](docs/CHANGELOG.md)** - L·ªãch s·ª≠ thay ƒë·ªïi d·ª± √°n

## üõ†Ô∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng

| Th√†nh ph·∫ßn        | C√¥ng ngh·ªá            | C·ªïng       | M√¥ t·∫£                             |
| ----------------- | -------------------- | ---------- | --------------------------------- |
| **C∆° s·ªü d·ªØ li·ªáu** | PostgreSQL 14        | 5432       | OLTP database v·ªõi CDC enabled     |
| **CDC**           | Debezium 2.5         | 8083       | Change Data Capture               |
| **Streaming**     | Apache Kafka         | 9092       | Message broker                    |
| **X·ª≠ l√Ω**         | Spark 3.4.1          | 8080       | X·ª≠ l√Ω stream & batch              |
| **L∆∞u tr·ªØ**       | Delta Lake + MinIO   | 9000, 9001 | ACID lakehouse                    |
| **Metastore**     | Hive Metastore 3.1.3 | 9083       | Cache metadata (t√πy ch·ªçn)         |
| **Truy v·∫•n**      | Trino                | 8085       | C√¥ng c·ª• SQL ph√¢n t√°n              |
| **ƒêi·ªÅu ph·ªëi**     | Airflow 2.8.0        | 8081       | L·∫≠p l·ªãch workflow                 |
| **Theo d√µi ML**   | MLflow 2.8.0         | 5001       | Theo d√µi m√¥ h√¨nh                  |
| **Tr·ª±c quan h√≥a** | Metabase             | 3000       | Dashboard BI                      |
| **API**           | FastAPI              | 8000       | D·ª± ƒëo√°n th·ªùi gian th·ª±c (t√πy ch·ªçn) |
| **Chatbot**       | Streamlit + Gemini   | 8501       | Chat v·ªõi database b·∫±ng ti·∫øng Vi·ªát |

## üìã Y√™u c·∫ßu h·ªá th·ªëng

**Ph·∫ßn c·ª©ng:**

- CPU: 6 cores minimum (khuy·∫øn ngh·ªã 8+)
- RAM: 10GB minimum (khuy·∫øn ngh·ªã 16GB)
- Disk: 30GB free space

**Ph·∫ßn m·ªÅm:**

- Docker Desktop 4.0+ (Windows/Mac) ho·∫∑c Docker Engine 20.10+ (Linux)
- Docker Compose 2.0+
- PowerShell 5.1+ (Windows) ho·∫∑c Bash (Linux/Mac)

**C·∫•u h√¨nh Docker (Windows WSL2):**

T·∫°o file `C:\Users\<YourUsername>\.wslconfig`:

```ini
[wsl2]
memory=10GB
processors=6
swap=4GB
```

Sau ƒë√≥ restart WSL2:

```powershell
wsl --shutdown
```

## üöÄ H∆∞·ªõng d·∫´n ch·∫°y

### 0. C·∫•u h√¨nh Gemini API (T√πy ch·ªçn - Cho Chatbot)

N·∫øu b·∫°n mu·ªën s·ª≠ d·ª•ng Chatbot, c·∫ßn c·∫•u h√¨nh Gemini API key (FREE):

**B∆∞·ªõc 1: L·∫•y API Key**

1. Truy c·∫≠p: https://aistudio.google.com/app/apikey
2. ƒêƒÉng nh·∫≠p Google
3. Click **"Create API Key"**
4. Copy API key (d·∫°ng: `AIzaSy...`)

**B∆∞·ªõc 2: T·∫°o file `.env`**

```bash
# Copy file m·∫´u
cp .env.example .env

# S·ª≠a file .env
notepad .env  # Windows
# ho·∫∑c
nano .env     # Linux/Mac
```

**B∆∞·ªõc 3: D√°n API key v√†o `.env`**

```bash
GOOGLE_API_KEY=AIzaSyXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
```

**L∆∞u √Ω:** N·∫øu kh√¥ng d√πng Chatbot, c√≥ th·ªÉ b·ªè qua b∆∞·ªõc n√†y.

---

### 1. T·∫£i m√£ ngu·ªìn

```bash
git clone https://github.com/bin-bard/real-time-fraud-detection-lakehouse.git
cd real-time-fraud-detection-lakehouse
```

### 2. Kh·ªüi ƒë·ªông h·ªá th·ªëng

```bash
docker compose up -d --build
```

**‚è≥ Th·ªùi gian kh·ªüi ƒë·ªông:** ~5-10 ph√∫t (t·∫£i images + kh·ªüi t·∫°o services)

### 3. T·∫£i d·ªØ li·ªáu v√† qu·∫£n l√Ω Data Producer

#### üìå **Data Producer c√≥ 2 ch·∫ø ƒë·ªô ho·∫°t ƒë·ªông:**

**üîπ IDLE MODE** (M·∫∑c ƒë·ªãnh - `MODE=idle`):

- Container ch·ªâ s·ªëng, **KH√îNG t·ª± ƒë·ªông** load data
- B·∫°n ph·∫£i ch·∫°y th·ªß c√¥ng qua `docker exec`
- D√πng cho: Bulk load ban ƒë·∫ßu, ki·ªÉm so√°t ho√†n to√†n

**üîπ AUTO-STREAM MODE** (B·ªè `MODE=idle`):

- Container **t·ª± ƒë·ªông streaming** khi start/restart
- D√πng cho: Sau khi ƒë√£ bulk load xong, mu·ªën stream li√™n t·ª•c

---

#### **A. Bulk Load Ban ƒê·∫ßu (Khuy·∫øn ngh·ªã - IDLE MODE)**

**B∆∞·ªõc 1: ƒê·∫£m b·∫£o IDLE MODE** (file `docker-compose.yml`):

```yaml
data-producer:
  environment:
    MODE: idle # ‚Üê ƒê·ªÉ IDLE mode
```

**B∆∞·ªõc 2: Bulk load 50K giao d·ªãch:**

```bash
# T·∫£i 50K giao d·ªãch (~250 giao d·ªãch gian l·∫≠n)
docker exec data-producer python producer.py --bulk-load 50000
```

**K·∫øt qu·∫£:**

- ‚úÖ ~50K b·∫£n ghi trong 2-3 ph√∫t
- ‚úÖ ~250 giao d·ªãch gian l·∫≠n (t·ª∑ l·ªá 0.5%)
- ‚úÖ ƒê·ªß d·ªØ li·ªáu cho hu·∫•n luy·ªán ML ngay
- ‚úÖ Checkpoint ƒë∆∞·ª£c l∆∞u, kh√¥ng tr√πng l·∫∑p khi ch·∫°y l·∫°i

---

#### **B. Chuy·ªÉn sang AUTO-STREAM MODE (Streaming li√™n t·ª•c)**

**Sau khi bulk load xong**, n·∫øu mu·ªën container **t·ª± ƒë·ªông streaming** khi stop/start:

**B∆∞·ªõc 1: S·ª≠a `docker-compose.yml`:**

```yaml
data-producer:
  environment:
    # MODE: idle  # ‚Üê Comment ho·∫∑c x√≥a d√≤ng n√†y
```

**B∆∞·ªõc 2: Restart container:**

```bash
docker compose up -d data-producer
```

**B∆∞·ªõc 3: Test auto-streaming:**

```bash
# Stop
docker stop data-producer

# Start ‚Üí T·ª± ƒë·ªông streaming
docker start data-producer

# Ho·∫∑c restart tr·ª±c ti·∫øp
docker restart data-producer
```

**K·∫øt qu·∫£:**

- ‚úÖ Container t·ª± ƒë·ªông ch·∫°y streaming mode
- ‚úÖ D·ªØ li·ªáu ƒë∆∞·ª£c load t·ª´ t·ª´ theo th·ªùi gian th·ª±c (TIME_SCALING_FACTOR = 0.001)
- ‚úÖ Ti·∫øp t·ª•c t·ª´ checkpoint, kh√¥ng tr√πng l·∫∑p

---

#### **C. Ch·∫°y Streaming th·ªß c√¥ng (IDLE MODE)**

N·∫øu v·∫´n gi·ªØ `MODE=idle`, mu·ªën streaming th·ªß c√¥ng:

```bash
docker exec -it data-producer python producer.py
```

**D·ª´ng streaming:** Nh·∫•n `Ctrl+C`

---

#### **üìã T√≥m t·∫Øt workflow:**

| M·ª•c ƒë√≠ch                    | C√°ch l√†m                                           |
| --------------------------- | -------------------------------------------------- |
| **Bulk load l·∫ßn ƒë·∫ßu**       | `MODE=idle` + `docker exec ... --bulk-load 50000`  |
| **Auto-stream khi restart** | X√≥a `MODE=idle` + `docker restart data-producer`   |
| **Streaming th·ªß c√¥ng**      | `MODE=idle` + `docker exec ... python producer.py` |
| **Reset checkpoint**        | `docker compose down -v` (x√≥a volumes)             |

### 4. Ki·ªÉm tra h·ªá th·ªëng

#### Ki·ªÉm tra services ƒëang ch·∫°y

```bash
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
```

**K·∫øt qu·∫£ mong ƒë·ª£i:** 15+ containers v·ªõi tr·∫°ng th√°i `Up`

#### Ki·ªÉm tra Bronze streaming

```bash
docker logs bronze-streaming --tail 20
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**

```
Batch 5 processing started
Writing 142 records to Bronze layer...
‚úÖ Batch 5 written successfully
```

#### Ki·ªÉm tra Airflow DAG

- Truy c·∫≠p: http://localhost:8081 (`admin` / `admin`)
- DAG: `lakehouse_pipeline_taskflow` (ch·∫°y m·ªói 5 ph√∫t)
- Ki·ªÉm tra: C√°c task Silver/Gold ch·∫°y th√†nh c√¥ng

#### Ki·ªÉm tra d·ªØ li·ªáu trong MinIO

- Truy c·∫≠p: http://localhost:9001 (`minio` / `minio123`)
- Bucket: `lakehouse`
- Ki·ªÉm tra c√°c th∆∞ m·ª•c: `bronze/`, `silver/`, `gold/`

#### Truy v·∫•n d·ªØ li·ªáu qua Trino

```bash
docker exec -it trino trino --server localhost:8081
```

```sql
-- Ki·ªÉm tra d·ªØ li·ªáu t·ªìn t·∫°i
SELECT COUNT(*) FROM delta.bronze.transactions;
SELECT COUNT(*) FROM delta.silver.transactions;
SELECT COUNT(*) FROM delta.gold.fact_transactions;

-- D·ªØ li·ªáu m·∫´u
SELECT * FROM delta.gold.fact_transactions LIMIT 5;

-- Ph√¢n b·ªë gian l·∫≠n
SELECT is_fraud, COUNT(*) as count
FROM delta.silver.transactions
GROUP BY is_fraud;

quit;
```

**‚ö†Ô∏è QUAN TR·ªåNG:** Truy v·∫•n d·ªØ li·ªáu ph·∫£i d√πng catalog **`delta`** (KH√îNG d√πng `hive`):

- ‚úÖ `delta.bronze.*`, `delta.silver.*`, `delta.gold.*`
- ‚ùå `hive.*` (ch·ªâ li·ªát k√™ b·∫£ng, kh√¥ng truy v·∫•n ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng Delta)

## üîë Truy c·∫≠p c√°c d·ªãch v·ª•

| D·ªãch v·ª•             | URL                   | T√™n ƒëƒÉng nh·∫≠p / M·∫≠t kh·∫©u | Ghi ch√∫                           |
| ------------------- | --------------------- | ------------------------ | --------------------------------- |
| **Airflow**         | http://localhost:8081 | `admin` / `admin`        | ƒêi·ªÅu ph·ªëi workflow                |
| **Spark Master UI** | http://localhost:8080 | -                        | Gi√°m s√°t c√°c job Spark            |
| **MinIO Console**   | http://localhost:9001 | `minio` / `minio123`     | L∆∞u tr·ªØ Data Lake                 |
| **MLflow UI**       | http://localhost:5001 | -                        | Theo d√µi m√¥ h√¨nh ML               |
| **Kafka UI**        | http://localhost:9002 | -                        | Topics, messages, consumer groups |
| **Trino UI**        | http://localhost:8085 | -                        | Gi√°m s√°t c√¥ng c·ª• truy v·∫•n         |
| **Metabase**        | http://localhost:3000 | (t·∫°o admin l·∫ßn ƒë·∫ßu)      | Dashboard BI                      |
| **PostgreSQL**      | localhost:5432        | `postgres` / `postgres`  | C∆° s·ªü d·ªØ li·ªáu ngu·ªìn               |
| **FastAPI**         | http://localhost:8000 | -                        | API d·ª± ƒëo√°n gian l·∫≠n real-time    |
| **Chatbot**         | http://localhost:8501 | -                        | Chat v·ªõi database (Gemini AI)     |

## üìä Ki·∫øn tr√∫c h·ªá th·ªëng

### Ki·∫øn tr√∫c Medallion (K·∫øt h·ª£p: Streaming + Batch)

```
PostgreSQL (Ngu·ªìn)
    ‚Üì Debezium CDC
Kafka (postgres.public.transactions)
    ‚Üì Bronze Streaming (Li√™n t·ª•c, ~195% CPU)
Bronze Delta Lake (s3a://lakehouse/bronze/)
    ‚Üì Silver Batch (M·ªói 5 ph√∫t qua Airflow)
Silver Delta Lake (s3a://lakehouse/silver/)
    ‚Üì Gold Batch (M·ªói 5 ph√∫t qua Airflow)
Gold Delta Lake (s3a://lakehouse/gold/) - 5 b·∫£ng
    ‚Üì
Trino Delta Catalog (Truy v·∫•n d·ªØ li·ªáu)
    ‚Üì
Metabase/DBeaver (Ph√¢n t√≠ch)
```

**C√°c l·ªõp d·ªØ li·ªáu:**

1. **Bronze** - D·ªØ li·ªáu CDC th√¥ (streaming th·ªùi gian th·ª±c)
2. **Silver** - L√†m s·∫°ch + K·ªπ thu·∫≠t ƒë·∫∑c tr∆∞ng (batch m·ªói 5 ph√∫t)
3. **Gold** - L∆∞·ª£c ƒë·ªì sao (Star Schema): 4 chi·ªÅu + 1 b·∫£ng s·ª± ki·ªán (batch m·ªói 5 ph√∫t)

**C√°c b·∫£ng l·ªõp Gold:**

- `dim_customer` - Chi·ªÅu kh√°ch h√†ng
- `dim_merchant` - Chi·ªÅu c·ª≠a h√†ng
- `dim_time` - Chi·ªÅu th·ªùi gian
- `dim_location` - Chi·ªÅu ƒë·ªãa ƒëi·ªÉm
- `fact_transactions` - S·ª± ki·ªán giao d·ªãch (25K+ b·∫£n ghi)

## ü§ñ Hu·∫•n luy·ªán ML

### Hu·∫•n luy·ªán t·ª± ƒë·ªông (Airflow)

- **L·ªãch tr√¨nh:** H√†ng ng√†y l√∫c 2 gi·ªù s√°ng
- **DAG:** `model_retraining_taskflow`
- **M√¥ h√¨nh:** RandomForest + LogisticRegression
- **Ch·ªâ s·ªë:** ƒê·ªô ch√≠nh x√°c, Precision, Recall, F1, AUC

### K√≠ch ho·∫°t th·ªß c√¥ng

Airflow UI ‚Üí `model_retraining_taskflow` ‚Üí ‚ñ∂Ô∏è Trigger DAG

### Qu·∫£n l√Ω t√†i nguy√™n

**Tr∆∞·ªõc khi ch·∫°y hu·∫•n luy·ªán ML:**

```powershell
# Gi·∫£i ph√≥ng ~2GB RAM + 1-2 CPU cores
.\scripts\prepare-ml-training.ps1
```

**Sau khi hu·∫•n luy·ªán xong:**

```powershell
# Kh√¥i ph·ª•c c√°c d·ªãch v·ª•
.\scripts\restore-services.ps1
```

### Ki·ªÉm tra m√¥ h√¨nh

- Truy c·∫≠p: http://localhost:5001
- Th√≠ nghi·ªám: `fraud_detection_production`
- Ki·ªÉm tra c√°c l·∫ßn ch·∫°y: RandomForest, LogisticRegression

### C√¢u h·ªèi th∆∞·ªùng g·∫∑p v·ªÅ m·∫´u hu·∫•n luy·ªán

**H·ªèi: T·∫°i sao ch·ªâ c√≥ ~15-20 m·∫´u hu·∫•n luy·ªán?**

**ƒê√°p:** ƒê√¢y l√† h√†nh vi ƒê√öNG v·ªõi ph√°t hi·ªán gian l·∫≠n th·ª±c t·∫ø!

| Ch·ªâ s·ªë                  | Gi√° tr·ªã      | Gi·∫£i th√≠ch                         |
| ----------------------- | ------------ | ---------------------------------- |
| T·ªïng b·∫£n ghi (Silver)   | ~4,200       | Sau v√†i ph√∫t streaming             |
| Giao d·ªãch gian l·∫≠n      | ~10 (0.24%)  | T·ª∑ l·ªá gian l·∫≠n th·ª±c t·∫ø 0.5%        |
| Sau c√¢n b·∫±ng l·ªõp        | 10 + 10 = 20 | Gi·∫£m m·∫´u l·ªõp ƒëa s·ªë xu·ªëng t·ª∑ l·ªá 1:1 |
| Chia train/test (80/20) | 16 + 4       | T·∫≠p d·ªØ li·ªáu cu·ªëi c√πng              |

**Gi·∫£i ph√°p:** T·∫£i h√†ng lo·∫°t 50K b·∫£n ghi ‚Üí ~250 m·∫´u gian l·∫≠n ‚Üí hu·∫•n luy·ªán t·ªët h∆°n

```bash
docker exec data-producer python producer.py --bulk-load 50000
```

## üîÆ API D·ª± ƒëo√°n Gian l·∫≠n (FastAPI)

### Gi·ªõi thi·ªáu

FastAPI service cung c·∫•p endpoint ƒë·ªÉ d·ª± ƒëo√°n gian l·∫≠n real-time s·ª≠ d·ª•ng model t·ª´ MLflow.

**T√≠nh nƒÉng:**

- ‚úÖ T·ª± ƒë·ªông load model t·ª´ MLflow Model Registry
- ‚úÖ Fallback sang rule-based n·∫øu model ch∆∞a c√≥
- ‚úÖ Batch prediction cho nhi·ªÅu giao d·ªãch
- ‚úÖ Reload model sau khi training m·ªõi
- ‚úÖ Health check v√† model info

### S·ª≠ d·ª•ng API

**1. Ki·ªÉm tra tr·∫°ng th√°i:**

```bash
curl http://localhost:8000/health
```

**2. Th√¥ng tin model:**

```bash
curl http://localhost:8000/model/info
```

**3. D·ª± ƒëo√°n ƒë∆°n l·∫ª:**

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "amt": 850.50,
    "log_amount": 6.75,
    "amount_bin": 3,
    "is_zero_amount": 0,
    "is_high_amount": 0,
    "distance_km": 120.5,
    "is_distant_transaction": 1,
    "age": 35,
    "gender_encoded": 1,
    "hour": 23,
    "day_of_week": 6,
    "is_weekend": 1,
    "is_late_night": 1,
    "hour_sin": -0.5,
    "hour_cos": 0.866,
    "trans_num": "T123456",
    "merchant": "fraud_Johnson-Stokes",
    "category": "gas_transport"
  }'
```

**Response:**

```json
{
  "trans_num": "T123456",
  "is_fraud_predicted": 1,
  "fraud_probability": 0.8523,
  "risk_level": "HIGH",
  "model_version": "mlflow_abc123"
}
```

**4. Reload model sau khi training:**

```bash
curl -X POST http://localhost:8000/model/reload
```

### T√≠ch h·ª£p v√†o Pipeline

**Use Cases (V√≠ d·ª• t√≠ch h·ª£p - ch∆∞a implement s·∫µn):**

```python
# 1. Alert System (T·ª± implement)
import requests
import smtplib

def check_and_alert(transaction_features):
    # G·ªçi API prediction
    response = requests.post(
        "http://fraud-detection-api:8000/predict",
        json=transaction_features
    )
    result = response.json()

    # G·ª≠i c·∫£nh b√°o n·∫øu HIGH risk
    if result["risk_level"] == "HIGH":
        send_email_alert(
            subject=f"‚ö†Ô∏è High Risk Transaction: {result['trans_num']}",
            body=f"Fraud Probability: {result['fraud_probability']:.2%}"
        )
        # Ho·∫∑c g·ª≠i Slack notification
        send_slack_alert(result)

# 2. Batch processing qua Spark
def predict_batch_spark(df):
    """Th√™m predictions v√†o Silver layer"""
    from pyspark.sql.functions import udf
    from pyspark.sql.types import StructType, DoubleType, StringType

    @udf(returnType=StructType([...]))
    def predict_udf(features):
        response = requests.post(
            "http://fraud-detection-api:8000/predict",
            json=features
        )
        return response.json()

    return df.withColumn("prediction", predict_udf(...))
```

**‚ö†Ô∏è L∆∞u √Ω:** Alert System (email/Slack) l√† **use case ƒë·ªÅ xu·∫•t**, CH∆ØA ƒë∆∞·ª£c implement s·∫µn trong d·ª± √°n. B·∫°n c·∫ßn t·ª± t√≠ch h·ª£p d·ª±a v√†o FastAPI response.

## üìä SQL Views cho Analytics

### T·∫°o Views trong Trino

File `sql/gold_layer_views_delta.sql` ch·ª©a 9 analytical views ƒë·ªÉ:

- Metabase query d·ªÖ h∆°n (kh√¥ng c·∫ßn JOIN ph·ª©c t·∫°p)
- Dashboard real-time metrics
- Chatbot query natural language

**C√°ch t·∫°o views:**

```bash
# 1. Connect v√†o Trino
docker exec -it trino trino --server localhost:8081

# 2. Copy-paste t·ª´ng CREATE VIEW statement t·ª´ file sql/gold_layer_views_delta.sql
# Ho·∫∑c ch·∫°y to√†n b·ªô file (n·∫øu Trino h·ªó tr·ª£)
```

**9 Views ƒë∆∞·ª£c t·∫°o:**

1. **`daily_summary`** - Metrics t·ªïng h·ª£p theo ng√†y

   ```sql
   SELECT * FROM delta.gold.daily_summary
   WHERE report_date >= CURRENT_DATE - INTERVAL '7' DAY;
   ```

2. **`hourly_summary`** - Ph√¢n t√≠ch patterns theo gi·ªù

   ```sql
   SELECT hour, fraud_rate FROM delta.gold.hourly_summary
   WHERE day = DAY(CURRENT_DATE)
   ORDER BY hour;
   ```

3. **`state_summary`** - Top states c√≥ fraud rate cao

   ```sql
   SELECT * FROM delta.gold.state_summary
   ORDER BY fraud_rate DESC LIMIT 10;
   ```

4. **`category_summary`** - Category n√†o r·ªßi ro nh·∫•t

   ```sql
   SELECT * FROM delta.gold.category_summary
   ORDER BY fraud_rate DESC;
   ```

5. **`amount_summary`** - Fraud rate theo kho·∫£ng ti·ªÅn

6. **`latest_metrics`** - Real-time metrics cho monitoring

   ```sql
   SELECT * FROM delta.gold.latest_metrics;
   -- C√≥ alert_level: HIGH/MEDIUM/LOW
   ```

7. **`fraud_patterns`** - Top fraud patterns

8. **`merchant_analysis`** - Merchants nguy hi·ªÉm nh·∫•t

9. **`time_period_analysis`** - Fraud rate theo Morning/Afternoon/Evening/Night

**S·ª≠ d·ª•ng trong Metabase:**

Sau khi t·∫°o views, query ƒë∆°n gi·∫£n h∆°n:

```sql
-- Thay v√¨ JOIN ph·ª©c t·∫°p:
-- SELECT ... FROM fact_transactions f
-- JOIN dim_customer c ON f.customer_key = c.customer_key
-- JOIN dim_merchant m ON ...

-- Ch·ªâ c·∫ßn:
SELECT * FROM delta.gold.daily_summary;
SELECT * FROM delta.gold.merchant_analysis;
```

## ü§ñ Chatbot - Chat v·ªõi Database b·∫±ng Ti·∫øng Vi·ªát

### Gi·ªõi thi·ªáu

Chatbot s·ª≠ d·ª•ng **Gemini AI** + **LangChain** ƒë·ªÉ chat v·ªõi database b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n.

**T√≠nh nƒÉng:**

- ‚úÖ Chat b·∫±ng ti·∫øng Vi·ªát ho·∫∑c ti·∫øng Anh
- ‚úÖ T·ª± ƒë·ªông sinh SQL query t·ª´ c√¢u h·ªèi
- ‚úÖ L∆∞u l·ªãch s·ª≠ chat v√†o PostgreSQL
- ‚úÖ Qu·∫£n l√Ω nhi·ªÅu sessions
- ‚úÖ Hi·ªÉn th·ªã SQL query ƒë∆∞·ª£c sinh ra
- ‚úÖ FREE tier (Gemini API mi·ªÖn ph√≠)

### Truy c·∫≠p Chatbot

```
http://localhost:8501
```

### C√¢u h·ªèi m·∫´u

**Ti·∫øng Vi·ªát:**

- "C√≥ bao nhi√™u giao d·ªãch gian l·∫≠n h√¥m nay?"
- "Top 5 bang c√≥ t·ª∑ l·ªá gian l·∫≠n cao nh·∫•t?"
- "Hi·ªÉn th·ªã fraud rate theo t·ª´ng gi·ªù trong ng√†y"
- "Merchant n√†o nguy hi·ªÉm nh·∫•t?"
- "T·ªïng s·ªë ti·ªÅn b·ªã gian l·∫≠n tu·∫ßn n√†y?"
- "Ph√¢n t√≠ch fraud patterns theo kho·∫£ng ti·ªÅn"
- "Category n√†o r·ªßi ro nh·∫•t?"
- "Danh s√°ch 10 giao d·ªãch gian l·∫≠n g·∫ßn ƒë√¢y"

**Ti·∫øng Anh:**

- "How many fraud transactions today?"
- "Which states have highest fraud rate?"
- "Show fraud rate by hour"
- "Top 10 risky merchants"
- "Total fraud amount this week"
- "Fraud patterns by amount range"

### Qu·∫£n l√Ω Chat History

**T√≠nh nƒÉng l∆∞u tr·ªØ:**

- M·ªói session ƒë∆∞·ª£c l∆∞u v√†o PostgreSQL
- C√≥ th·ªÉ load l·∫°i conversations c≈©
- X√≥a sessions kh√¥ng c·∫ßn thi·∫øt
- Theo d√µi s·ªë l∆∞·ª£ng messages m·ªói session

**Database schema:**

```sql
-- B·∫£ng chat_history t·ª± ƒë·ªông ƒë∆∞·ª£c t·∫°o
CREATE TABLE chat_history (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(100),
    role VARCHAR(20),  -- 'user' or 'assistant'
    message TEXT,
    sql_query TEXT,    -- SQL ƒë∆∞·ª£c sinh ra
    created_at TIMESTAMP
);
```

**Load l·∫°i conversation:**

1. M·ªü Chatbot sidebar
2. Ch·ªçn session t·ª´ "Sessions g·∫ßn ƒë√¢y"
3. T·∫•t c·∫£ messages s·∫Ω ƒë∆∞·ª£c load

### Troubleshooting

**L·ªói: "GOOGLE_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh"**

```bash
# 1. Ki·ªÉm tra file .env t·ªìn t·∫°i
ls .env

# 2. Ki·ªÉm tra n·ªôi dung
cat .env

# 3. ƒê·∫£m b·∫£o c√≥ d√≤ng:
GOOGLE_API_KEY=AIzaSy...

# 4. Restart chatbot container
docker compose restart fraud-chatbot
```

**L·ªói: "Cannot connect to Trino"**

```bash
# Ki·ªÉm tra Trino ƒëang ch·∫°y
docker ps | grep trino

# Test connection
docker exec fraud-chatbot python -c "
from sqlalchemy import create_engine
engine = create_engine('trino://trino:8081/delta/gold')
print(engine.table_names())
"
```

**Chatbot response ch·∫≠m?**

- Gemini API FREE tier c√≥ rate limit
- Model `gemini-2.0-flash-exp` l√† nhanh nh·∫•t
- C√≥ th·ªÉ ƒë·ªïi sang `gemini-1.5-flash` trong `chatbot.py`

## üîß K·∫øt n·ªëi Metabase

### C·∫•u h√¨nh c∆° s·ªü d·ªØ li·ªáu

```yaml
Lo·∫°i c∆° s·ªü d·ªØ li·ªáu: Trino
T√™n hi·ªÉn th·ªã: Fraud Detection Lakehouse

K·∫øt n·ªëi:
  Host: trino # N·∫øu Metabase ch·∫°y trong Docker
  # Host: localhost   # N·∫øu Metabase ch·∫°y ngo√†i Docker
  Port: 8081 # C·ªïng n·ªôi b·ªô (8085 cho b√™n ngo√†i)
  Catalog: delta # ‚ö†Ô∏è QUAN TR·ªåNG: D√πng delta, kh√¥ng ph·∫£i hive
  Database: gold # Ho·∫∑c 'silver'/'bronze'

X√°c th·ª±c:
  Username: (ƒë·ªÉ tr·ªëng)
  Password: (ƒë·ªÉ tr·ªëng)
```

### Truy v·∫•n m·∫´u

```sql
-- T·ª∑ l·ªá gian l·∫≠n theo danh m·ª•c
SELECT
    transaction_category,
    COUNT(*) as total_transactions,
    SUM(CASE WHEN is_fraud = 1 THEN 1 ELSE 0 END) as fraud_count,
    ROUND(100.0 * SUM(CASE WHEN is_fraud = 1 THEN 1 ELSE 0 END) / COUNT(*), 2) as fraud_rate
FROM delta.gold.fact_transactions
GROUP BY transaction_category
ORDER BY fraud_rate DESC

-- Top 10 c·ª≠a h√†ng r·ªßi ro cao
SELECT
    merchant_name,
    merchant_category,
    COUNT(*) as total_transactions,
    SUM(CASE WHEN is_fraud = 1 THEN 1 ELSE 0 END) as fraud_count
FROM delta.gold.fact_transactions
GROUP BY merchant_name, merchant_category
HAVING COUNT(*) > 10
ORDER BY fraud_count DESC
LIMIT 10
```

## üîß K·∫øt n·ªëi DBeaver/SQL Client

**JDBC URL:**

```
jdbc:trino://localhost:8085/delta
```

**C√†i ƒë·∫∑t k·∫øt n·ªëi:**

- Host: `localhost`
- C·ªïng: `8085`
- Database/Catalog: `delta`
- Schema: `gold` (ho·∫∑c `silver`, `bronze`)
- T√™n ƒëƒÉng nh·∫≠p: `trino` (ho·∫∑c b·∫•t k·ª≥)
- M·∫≠t kh·∫©u: (ƒë·ªÉ tr·ªëng)

## üêõ X·ª≠ l√Ω s·ª± c·ªë

### FastAPI kh√¥ng k·∫øt n·ªëi MLflow

```bash
# 1. Ki·ªÉm tra MLflow c√≥ ch·∫°y
docker logs mlflow --tail 20

# 2. Ki·ªÉm tra FastAPI logs
docker logs fraud-detection-api --tail 50

# 3. Test API
curl http://localhost:8000/health

# 4. Reload model sau khi training xong
curl -X POST http://localhost:8000/model/reload
```

### S·ª≠ d·ª•ng CPU cao (>500%)

**B√¨nh th∆∞·ªùng:**

- `bronze-streaming`: ~195% CPU (li√™n t·ª•c)
- `spark-master`: ~50-100% CPU khi ch·∫°y job
- `airflow-*`: ~10-30% CPU

**N·∫øu >600%:** Kh·ªüi ƒë·ªông l·∫°i d·ªãch v·ª•

```bash
docker compose restart bronze-streaming spark-master spark-worker
```

### Kh√¥ng c√≥ d·ªØ li·ªáu trong Silver/Gold

```bash
# 1. Ki·ªÉm tra Bronze c√≥ d·ªØ li·ªáu
docker exec trino trino --server localhost:8081 --execute "SELECT COUNT(*) FROM delta.bronze.transactions"

# 2. Ki·ªÉm tra Airflow DAG ƒëang ch·∫°y
# Airflow UI: http://localhost:8081 ‚Üí lakehouse_pipeline_taskflow

# 3. Ki·ªÉm tra logs
docker logs airflow-scheduler --tail 50
```

### MLflow tr·ªëng (kh√¥ng c√≥ m√¥ h√¨nh)

```bash
# 1. Ki·ªÉm tra Silver c√≥ ƒë·ªß d·ªØ li·ªáu (c·∫ßn √≠t nh·∫•t 1000 b·∫£n ghi v·ªõi m·∫´u gian l·∫≠n)
docker exec trino trino --server localhost:8081 --execute "SELECT is_fraud, COUNT(*) FROM delta.silver.transactions GROUP BY is_fraud"

# 2. K√≠ch ho·∫°t DAG hu·∫•n luy·ªán
# Airflow UI ‚Üí model_retraining_taskflow ‚Üí Trigger DAG

# 3. Ki·ªÉm tra logs
# Airflow UI ‚Üí model_retraining_taskflow ‚Üí train_ml_models ‚Üí Logs
```

### Kh·ªüi ƒë·ªông l·∫°i to√†n b·ªô h·ªá th·ªëng

```bash
# ‚ö†Ô∏è C·∫£nh b√°o: X√≥a to√†n b·ªô d·ªØ li·ªáu!
docker compose down -v
docker compose up -d --build
```

## üìñ T√†i li·ªáu

- **[PROJECT_SPECIFICATION.md](docs/PROJECT_SPECIFICATION.md)** - ƒê·∫∑c t·∫£ chi ti·∫øt ki·∫øn tr√∫c, lu·ªìng d·ªØ li·ªáu, y√™u c·∫ßu
- **[CHANGELOG.md](docs/CHANGELOG.md)** - L·ªãch s·ª≠ c·∫≠p nh·∫≠t, l·ªói ƒë√£ s·ª≠a, c√¢u h·ªèi th∆∞·ªùng g·∫∑p

## üìù Gi·∫•y ph√©p

**Gi·∫•y ph√©p MIT (MIT License)**

Copyright (c) 2025 Nh√≥m 6 - GVHD: ThS. Phan Th·ªã Th·ªÉ

Gi·∫•y ph√©p n√†y cho ph√©p b·∫•t k·ª≥ ai c√≥ ƒë∆∞·ª£c b·∫£n sao c·ªßa ph·∫ßn m·ªÅm v√† t√†i li·ªáu li√™n quan ("Ph·∫ßn m·ªÅm") ƒë∆∞·ª£c ph√©p s·ª≠ d·ª•ng Ph·∫ßn m·ªÅm m√† kh√¥ng b·ªã h·∫°n ch·∫ø, bao g·ªìm nh∆∞ng kh√¥ng gi·ªõi h·∫°n quy·ªÅn s·ª≠ d·ª•ng, sao ch√©p, s·ª≠a ƒë·ªïi, h·ª£p nh·∫•t, xu·∫•t b·∫£n, ph√¢n ph·ªëi, c·∫•p ph√©p con v√†/ho·∫∑c b√°n c√°c b·∫£n sao c·ªßa Ph·∫ßn m·ªÅm, v·ªõi c√°c ƒëi·ªÅu ki·ªán sau:

Th√¥ng b√°o b·∫£n quy·ªÅn tr√™n v√† th√¥ng b√°o gi·∫•y ph√©p n√†y ph·∫£i ƒë∆∞·ª£c bao g·ªìm trong t·∫•t c·∫£ c√°c b·∫£n sao ho·∫∑c ph·∫ßn quan tr·ªçng c·ªßa Ph·∫ßn m·ªÅm.

PH·∫¶N M·ªÄM ƒê∆Ø·ª¢C CUNG C·∫§P "NGUY√äN TR·∫†NG", KH√îNG C√ì B·∫¢O H√ÄNH D∆Ø·ªöI B·∫§T K·ª≤ H√åNH TH·ª®C N√ÄO, R√ï R√ÄNG HO·∫∂C NG·ª§ √ù, BAO G·ªíM NH∆ØNG KH√îNG GI·ªöI H·∫†N B·∫¢O H√ÄNH V·ªÄ KH·∫¢ NƒÇNG TH∆Ø∆†NG M·∫†I, PH√ô H·ª¢P CHO M·ªòT M·ª§C ƒê√çCH C·ª§ TH·ªÇ V√Ä KH√îNG VI PH·∫†M. TRONG B·∫§T K·ª≤ TR∆Ø·ªúNG H·ª¢P N√ÄO, T√ÅC GI·∫¢ HO·∫∂C CH·ª¶ S·ªû H·ªÆU B·∫¢N QUY·ªÄN KH√îNG CH·ªäU TR√ÅCH NHI·ªÜM V·ªÄ B·∫§T K·ª≤ Y√äU C·∫¶U, THI·ªÜT H·∫†I HO·∫∂C TR√ÅCH NHI·ªÜM PH√ÅP L√ù N√ÄO.

## üë• Th√†nh vi√™n nh√≥m

- Nguy·ªÖn Thanh T√†i - 22133049
- V√µ Tri·ªáu Ph√∫c - 22133043
