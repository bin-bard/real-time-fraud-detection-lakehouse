{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe5581d",
   "metadata": {},
   "source": [
    "## Data Lakehouse Exploration\n",
    "\n",
    "Kh√°m ph√° d·ªØ li·ªáu ·ªü c√°c t·∫ßng Bronze, Silver v√† Gold trong Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c9e259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark Session created successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Spark ƒë·ªÉ k·∫øt n·ªëi ƒë·∫øn MinIO v√† Delta Lake\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, count, avg, sum, when\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# T·∫°o Spark Session v·ªõi Delta Lake v√† S3 (MinIO)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataLakehouseExploration\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark Session created successfully!\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4aaf4d",
   "metadata": {},
   "source": [
    "### 1. Bronze Layer - Raw Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa93bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Bronze layer not available: An error occurred while calling o42.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: delta. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.ClassNotFoundException: delta.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 15 more\n",
      "\n",
      "üí° Make sure data-producer is running and Bronze layer job has been executed\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ Bronze layer\n",
    "try:\n",
    "    bronze_df = spark.read.format(\"delta\").load(\"s3a://lakehouse/bronze/transactions\")\n",
    "    \n",
    "    print(\"üìä BRONZE LAYER OVERVIEW\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total records: {bronze_df.count():,}\")\n",
    "    print(f\"Columns: {len(bronze_df.columns)}\")\n",
    "    print(\"\\nüìã Schema:\")\n",
    "    bronze_df.printSchema()\n",
    "    \n",
    "    print(\"\\nüìù Sample data:\")\n",
    "    bronze_df.show(5, truncate=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Bronze layer not available: {e}\")\n",
    "    print(\"üí° Make sure data-producer is running and Bronze layer job has been executed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb9482",
   "metadata": {},
   "source": [
    "### 2. Silver Layer - Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc30dcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Silver layer not available: An error occurred while calling o46.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: delta. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.ClassNotFoundException: delta.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 15 more\n",
      "\n",
      "üí° Make sure Silver layer job has been executed\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ Silver layer\n",
    "try:\n",
    "    silver_df = spark.read.format(\"delta\").load(\"s3a://lakehouse/silver/transactions\")\n",
    "    \n",
    "    print(\"ü•à SILVER LAYER OVERVIEW\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total records: {silver_df.count():,}\")\n",
    "    print(f\"Columns: {len(silver_df.columns)}\")\n",
    "    \n",
    "    print(\"\\nüìã Schema:\")\n",
    "    silver_df.printSchema()\n",
    "    \n",
    "    # Ki·ªÉm tra c√°c features ƒë∆∞·ª£c engineer\n",
    "    engineered_features = [\n",
    "        'distance_km', 'age', 'hour', 'day_of_week', 'is_weekend', \n",
    "        'hour_sin', 'hour_cos', 'log_amount', 'is_zero_amount', \n",
    "        'is_high_amount', 'amount_bin', 'gender_encoded', \n",
    "        'is_distant_transaction', 'is_late_night'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüîß Engineered Features:\")\n",
    "    for feature in engineered_features:\n",
    "        if feature in silver_df.columns:\n",
    "            print(f\"  ‚úÖ {feature}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {feature} - Missing\")\n",
    "    \n",
    "    print(\"\\nüìä Feature Statistics:\")\n",
    "    silver_df.select(*engineered_features[:5]).describe().show()\n",
    "    \n",
    "    print(\"\\nüìù Sample data (first 3 rows):\")\n",
    "    silver_df.select(\"trans_num\", \"amt\", \"is_fraud\", *engineered_features[:5]).show(3)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Silver layer not available: {e}\")\n",
    "    print(\"üí° Make sure Silver layer job has been executed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e24572c",
   "metadata": {},
   "source": [
    "### 3. Gold Layer - Dimensional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf0ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ Gold layer (Dimensional Model)\n",
    "gold_tables = [\n",
    "    \"dim_customer\", \"dim_merchant\", \"dim_time\", \"dim_location\", \"fact_transactions\"\n",
    "]\n",
    "\n",
    "print(\"ü•á GOLD LAYER OVERVIEW (Dimensional Model)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for table in gold_tables:\n",
    "    try:\n",
    "        df = spark.read.format(\"delta\").load(f\"s3a://lakehouse/gold/{table}\")\n",
    "        \n",
    "        print(f\"\\nüìä {table.upper()}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Records: {df.count():,}\")\n",
    "        print(f\"Columns: {len(df.columns)}\")\n",
    "        print(f\"Schema: {[col for col in df.columns]}\")\n",
    "        \n",
    "        # Show sample data\n",
    "        print(\"Sample data:\")\n",
    "        df.show(3, truncate=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå {table}: Not available - {e}\")\n",
    "        print(\"üí° Make sure Gold layer job has been executed\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72221a4",
   "metadata": {},
   "source": [
    "### 4. Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1489db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu qua c√°c t·∫ßng\n",
    "def analyze_data_quality(df, layer_name):\n",
    "    print(f\"\\nüìä {layer_name} - Data Quality Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    total_rows = df.count()\n",
    "    print(f\"Total rows: {total_rows:,}\")\n",
    "    \n",
    "    # Ki·ªÉm tra NULL values\n",
    "    print(\"\\nüîç NULL Values:\")\n",
    "    for col_name in df.columns:\n",
    "        null_count = df.filter(col(col_name).isNull()).count()\n",
    "        null_percentage = (null_count / total_rows) * 100 if total_rows > 0 else 0\n",
    "        if null_count > 0:\n",
    "            print(f\"  {col_name}: {null_count:,} ({null_percentage:.2f}%)\")\n",
    "    \n",
    "    # Ki·ªÉm tra fraud distribution n·∫øu c√≥ column is_fraud\n",
    "    if 'is_fraud' in df.columns:\n",
    "        print(\"\\nüö® Fraud Distribution:\")\n",
    "        fraud_stats = df.groupBy(\"is_fraud\").count().collect()\n",
    "        for row in fraud_stats:\n",
    "            fraud_percentage = (row['count'] / total_rows) * 100\n",
    "            fraud_label = \"Fraud\" if row['is_fraud'] else \"Normal\"\n",
    "            print(f\"  {fraud_label}: {row['count']:,} ({fraud_percentage:.2f}%)\")\n",
    "\n",
    "# Analyze each layer if available\n",
    "try:\n",
    "    if 'bronze_df' in locals():\n",
    "        analyze_data_quality(bronze_df, \"BRONZE LAYER\")\n",
    "except:\n",
    "    print(\"‚ùå Bronze layer not available for analysis\")\n",
    "\n",
    "try:\n",
    "    if 'silver_df' in locals():\n",
    "        analyze_data_quality(silver_df, \"SILVER LAYER\")\n",
    "except:\n",
    "    print(\"‚ùå Silver layer not available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62211599",
   "metadata": {},
   "source": [
    "### 5. Feature Analysis for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch features cho Machine Learning (n·∫øu Silver layer available)\n",
    "if 'silver_df' in locals() and silver_df is not None:\n",
    "    print(\"ü§ñ FEATURE ANALYSIS FOR MACHINE LEARNING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ML Features ƒë∆∞·ª£c s·ª≠ d·ª•ng trong training\n",
    "    ml_features = [\n",
    "        'amt', 'hour', 'day_of_week', 'log_amount', 'amount_bin', \n",
    "        'is_zero_amount', 'is_high_amount', 'distance_km', \n",
    "        'is_distant_transaction', 'age', 'gender_encoded', \n",
    "        'is_weekend', 'is_late_night', 'hour_sin', 'hour_cos'\n",
    "    ]\n",
    "    \n",
    "    available_features = [f for f in ml_features if f in silver_df.columns]\n",
    "    missing_features = [f for f in ml_features if f not in silver_df.columns]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Available ML Features ({len(available_features)}/{len(ml_features)}):\")\n",
    "    for feature in available_features:\n",
    "        print(f\"  ‚úÖ {feature}\")\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"\\n‚ùå Missing ML Features ({len(missing_features)}):\")\n",
    "        for feature in missing_features:\n",
    "            print(f\"  ‚ùå {feature}\")\n",
    "    \n",
    "    # Feature distributions by fraud class\n",
    "    if available_features and 'is_fraud' in silver_df.columns:\n",
    "        print(f\"\\nüìä Feature Statistics by Fraud Class:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # T√≠nh to√°n th·ªëng k√™ cho m·ªôt v√†i features quan tr·ªçng\n",
    "        important_features = ['amt', 'distance_km', 'age', 'hour']\n",
    "        \n",
    "        for feature in important_features:\n",
    "            if feature in silver_df.columns:\n",
    "                stats = silver_df.groupBy(\"is_fraud\") \\\n",
    "                    .agg(\n",
    "                        avg(feature).alias(f\"avg_{feature}\"),\n",
    "                        count(feature).alias(\"count\")\n",
    "                    ).collect()\n",
    "                \n",
    "                print(f\"\\n{feature.upper()}:\")\n",
    "                for row in stats:\n",
    "                    fraud_label = \"Fraud\" if row['is_fraud'] else \"Normal\"\n",
    "                    avg_val = row[f'avg_{feature}'] if row[f'avg_{feature}'] else 0\n",
    "                    print(f\"  {fraud_label}: avg={avg_val:.2f}, count={row['count']:,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Silver layer not available for ML feature analysis\")\n",
    "    print(\"üí° Run Silver layer job first to see feature analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf989ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "spark.stop()\n",
    "print(\"‚úÖ Spark session stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
