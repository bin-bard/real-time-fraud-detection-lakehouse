# Real-Time Fraud Detection Architecture

## üìä Ki·∫øn tr√∫c t·ªïng quan

### **1. Real-Time Detection Flow (< 1s)**

```
Kafka CDC ‚Üí Bronze (Spark Streaming) ‚Üí PostgreSQL transactions ‚Üí FastAPI Prediction ‚Üí fraud_predictions table
```

### **2. Chatbot/Manual Prediction Flow**

```
User Input ‚Üí Chatbot/UI ‚Üí FastAPI Prediction ‚Üí Response (NOT saved to DB)
```

---

## üîÑ Data Flow Chi Ti·∫øt

### **A. Real-Time Flow (Production)**

1. **Transaction occurs** ‚Üí Kafka CDC captures from source DB
2. **Bronze layer** (Spark Streaming) receives Kafka event
3. **Insert to PostgreSQL** `transactions` table
4. **Trigger prediction** ‚Üí Call FastAPI `/predict/explained`
5. **Save prediction** ‚Üí Insert to `fraud_predictions` table
6. **Alert if fraud** ‚Üí Dashboard/notification

**Characteristics:**

- ‚úÖ Has `trans_num` in `transactions` table
- ‚úÖ Satisfies foreign key constraint
- ‚úÖ Saved to `fraud_predictions`
- ‚ö° Response time: < 1s

---

### **B. Chatbot/Manual Flow (Interactive)**

1. **User asks** ‚Üí "D·ª± ƒëo√°n giao d·ªãch $850 l√∫c 2h s√°ng"
2. **Agent calls** ‚Üí `PredictFraud` tool
3. **API predicts** ‚Üí FastAPI with `trans_num = CHAT_*`
4. **Returns result** ‚Üí Display in chatbot
5. **NOT saved** ‚Üí API skips DB save (no transaction record)

**Characteristics:**

- ‚ùå No `trans_num` in `transactions` table (hypothetical)
- ‚è≠Ô∏è Skipped by API (`trans_num.startswith('CHAT_')`)
- ‚ùå NOT saved to `fraud_predictions`
- üéØ Purpose: Exploration & what-if analysis

---

## üóÑÔ∏è Database Schema

### **fraud_predictions Table**

```sql
CREATE TABLE fraud_predictions (
    id SERIAL PRIMARY KEY,
    trans_num VARCHAR(100) UNIQUE NOT NULL,
    prediction_score NUMERIC(5,4),
    is_fraud_predicted SMALLINT,
    model_version VARCHAR(50),
    prediction_time TIMESTAMP DEFAULT NOW(),

    -- Foreign key: Only real transactions can be saved
    CONSTRAINT fraud_predictions_trans_num_fkey
    FOREIGN KEY (trans_num) REFERENCES transactions(trans_num)
);
```

**Purpose:** Store predictions for **real transactions only**

---

## üîß API Logic (fraud-detection-api)

### **save_prediction_to_db() Function**

```python
def save_prediction_to_db(trans_num: str, ...):
    # Skip chatbot/manual predictions
    if trans_num.startswith(('CHAT_', 'MANUAL_')):
        logger.info(f"‚è≠Ô∏è Skipping DB save for manual prediction: {trans_num}")
        return True  # Return success but don't save

    # Skip rule-based fallback
    if "rule_based" in model_ver.lower():
        logger.info(f"‚è≠Ô∏è Skipping DB save for rule-based")
        return True

    # Real transactions: Save to DB
    INSERT INTO fraud_predictions ...
```

---

## üöÄ Future Integration Steps

### **Step 1: Setup Kafka CDC**

- Configure Debezium connector for source database
- Topic: `transactions-topic`

### **Step 2: Spark Streaming Job**

```python
# bronze_streaming_job.py
df = spark.readStream \
    .format("kafka") \
    .option("subscribe", "transactions-topic") \
    .load()

# Parse and transform
transactions = df.selectExpr("CAST(value AS STRING)")

# Write to PostgreSQL
transactions.writeStream \
    .foreachBatch(lambda batch, _: insert_and_predict(batch)) \
    .start()

def insert_and_predict(batch_df):
    # 1. Insert to PostgreSQL transactions table
    batch_df.write.jdbc(...)

    # 2. Call FastAPI for each transaction
    for row in batch_df.collect():
        response = requests.post(
            "http://fraud-detection-api:8000/predict/explained",
            json=row.asDict()
        )
```

### **Step 3: Dashboard Real-Time Monitoring**

- Show live predictions from `fraud_predictions` table
- Alert on high-risk transactions
- Metrics: fraud rate, model performance

---

## üìà Monitoring & Metrics

### **Queries for Monitoring**

```sql
-- Real-time prediction count (last 1 hour)
SELECT
    COUNT(*) as predictions_count,
    SUM(is_fraud_predicted) as fraud_count,
    model_version
FROM fraud_predictions
WHERE prediction_time > NOW() - INTERVAL '1 hour'
GROUP BY model_version;

-- Average prediction time
SELECT
    DATE_TRUNC('minute', prediction_time) as minute,
    COUNT(*) as predictions_per_minute,
    AVG(prediction_score) as avg_fraud_score
FROM fraud_predictions
WHERE prediction_time > NOW() - INTERVAL '1 hour'
GROUP BY minute
ORDER BY minute DESC;

-- High-risk transactions
SELECT *
FROM fraud_predictions fp
JOIN transactions t ON fp.trans_num = t.trans_num
WHERE fp.is_fraud_predicted = 1
  AND fp.prediction_score > 0.7
ORDER BY fp.prediction_time DESC
LIMIT 20;
```

---

## ‚úÖ Current State

- ‚úÖ API logic: Skip chatbot/manual predictions
- ‚úÖ Database: Foreign key constraint preserved
- ‚úÖ Chatbot: Works without DB save
- ‚è≥ Kafka integration: Pending
- ‚è≥ Spark streaming: Pending
- ‚è≥ Real-time dashboard: Pending

---

## üéØ Benefits

1. **Data Integrity**: Foreign key ensures only valid transactions stored
2. **Flexibility**: Chatbot can predict hypothetical scenarios
3. **Scalability**: Ready for real-time Kafka integration
4. **Clean Separation**: Real vs Manual predictions clearly distinguished
5. **Performance**: Chatbot doesn't wait for DB writes

---

## üö® Alert Destinations

Khi ph√°t hi·ªán giao d·ªãch **GIAN L·∫¨N** (b·∫•t k·ª≥ risk level n√†o: LOW/MEDIUM/HIGH), h·ªá th·ªëng s·∫Ω g·ª≠i alert ƒë·∫øn:

### **1. Slack Webhook** ‚≠ê (ƒê√£ tri·ªÉn khai)

**Configuration in `.env`:**

```bash
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/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
```

**Alert Policy:**

- ‚úÖ **ALL fraud detections** (kh√¥ng ch·ªâ HIGH)
- üî¥ HIGH RISK: fraud_probability > 70%
- üü° MEDIUM RISK: fraud_probability 40-70%
- üü¢ LOW RISK: fraud_probability < 40% but is_fraud=1

**Alert Format:**

```
üö® FRAUD DETECTED üî¥

üî¥ Fraud Alert - HIGH Risk

Transaction ID: T123456789
Amount: $1,850.00
Customer: John Doe
Merchant: Suspicious Electronics Store
Fraud Probability: 95.2%
Risk Level: HIGH

üìç Location: New York, NY

ü§ñ AI Analysis:
Giao d·ªãch xa 4000km, l√∫c 2h s√°ng, s·ªë ti·ªÅn l·ªõn $1850.
Model ph√°t hi·ªán pattern b·∫•t th∆∞·ªùng.

‚è∞ Detected at: 2025-12-10 15:30:45
```

**Setup:**

1. ‚úÖ ƒê√£ c√≥ Slack webhook URL trong `.env`
2. ‚úÖ Service ƒë√£ configure trong `docker-compose.yml`
3. ‚úÖ Streaming job t·ª± ƒë·ªông g·ª≠i alert

---

### **2. PostgreSQL `fraud_predictions` Table** (Primary Storage)

T·∫•t c·∫£ predictions ƒë∆∞·ª£c l∆∞u v√†o database:

```sql
CREATE TABLE fraud_predictions (
    id SERIAL PRIMARY KEY,
    trans_num VARCHAR(100) UNIQUE NOT NULL,
    prediction_score NUMERIC(5, 4),
    is_fraud_predicted SMALLINT,
    model_version VARCHAR(50),
    prediction_time TIMESTAMP DEFAULT NOW(),

    CONSTRAINT fraud_predictions_trans_num_fkey
    FOREIGN KEY (trans_num) REFERENCES transactions(trans_num)
);
```

**Query predictions:**

```sql
-- All fraud predictions today
SELECT * FROM fraud_predictions
WHERE is_fraud_predicted = 1
  AND prediction_time >= CURRENT_DATE
ORDER BY prediction_score DESC;

-- HIGH risk only
SELECT
    fp.*,
    t.amt,
    t.merchant,
    t.first || ' ' || t.last AS customer
FROM fraud_predictions fp
JOIN transactions t ON fp.trans_num = t.trans_num
WHERE fp.prediction_score > 0.7
  AND fp.is_fraud_predicted = 1
ORDER BY fp.prediction_time DESC;
```

---

## ‚úÖ Implementation Status

### **Completed:**

1. ‚úÖ **Spark Streaming Job** (`spark/app/realtime_prediction_job.py`)

   - Reads from Kafka CDC
   - Inserts to PostgreSQL `transactions`
   - Calls FastAPI `/predict/raw`
   - Saves to `fraud_predictions`
   - Sends Slack alert for ALL fraud

2. ‚úÖ **Docker Compose Service** (`spark-realtime-prediction`)

   - Auto-starts with dependencies
   - Configured with Slack webhook
   - 10-second micro-batching
   - Auto-restart enabled

3. ‚úÖ **Alert Logic**

   - Policy: Alert on **ALL fraud** (is_fraud=1)
   - Color-coded by risk: üî¥ HIGH, üü° MEDIUM, üü¢ LOW
   - Rich Slack message with AI explanation

4. ‚úÖ **Test Script** (`scripts/test-realtime-flow.ps1`)
   - Inserts 4 test transactions
   - Monitors streaming logs
   - Verifies database predictions
   - Checks Slack delivery

---

## üöÄ Quick Start

### **1. Start Real-Time Detection**

```powershell
# Start streaming service
docker-compose up -d spark-realtime-prediction

# Verify running
docker logs spark-realtime-prediction --tail 50
```

**Expected output:**

```
üöÄ Starting Real-Time Fraud Detection Streaming...
üì° Kafka Broker: kafka:9092
üìã Kafka Topic: postgres.public.transactions
üîÆ API Endpoint: http://fraud-detection-api:8000
üí¨ Slack Alerts: Enabled
üéØ Alert Policy: ALL fraud detections (LOW/MEDIUM/HIGH)
================================================================================
‚úÖ Streaming query started successfully
‚è≥ Waiting for Kafka events...
```

### **2. Test with Sample Transactions**

```powershell
# Run test script
.\scripts\test-realtime-flow.ps1
```

**What happens:**

1. Inserts 4 transactions (3 fraud + 1 normal)
2. Debezium captures CDC events
3. Kafka receives messages
4. Spark Streaming processes batch
5. API predicts fraud probability
6. Saves to `fraud_predictions` table
7. **Sends 3 Slack alerts** (one for each fraud)

### **3. Verify Slack Alerts**

Check your Slack channel for 3 alerts:

- üî¥ **HIGH RISK**: $1,850 at Suspicious Electronics Store (distant + late night)
- üü° **MEDIUM RISK**: $350 at Regular Grocery Store (medium amount)
- üü¢ **LOW RISK**: $85 at Local Coffee Shop (small amount but flagged)

### **1. Slack Webhook** ‚≠ê (Khuy·∫øn ngh·ªã)

```yaml
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXX
```

**Setup:**

1. T·∫°o Slack App t·∫°i https://api.slack.com/apps
2. Add Incoming Webhook
3. Copy webhook URL v√†o `.env`

**Alert format:**

```
üö® HIGH RISK FRAUD DETECTED üö®

Transaction: T123456789
Amount: $1,200.50
Customer: John Doe
Merchant: Suspicious Shop
Risk: HIGH (95.2%)

Explanation: Giao d·ªãch xa 200km, l√∫c 2h s√°ng, s·ªë ti·ªÅn l·ªõn
```

---

### **2. Email (SMTP)**

```yaml
SMTP_SERVER=smtp.gmail.com
SMTP_USER=alerts@company.com
SMTP_PASSWORD=app-password
ALERT_EMAIL=fraud-team@company.com
```

**Gmail setup:**

1. Enable 2FA
2. Generate App Password
3. Use App Password in `.env`

---

### **3. PostgreSQL Alert Queue** (Fallback)

N·∫øu Slack/Email fail, alert ƒë∆∞·ª£c l∆∞u v√†o b·∫£ng [`alert_queue`](database/init_postgres.sql):

```sql
CREATE TABLE alert_queue (
    id SERIAL PRIMARY KEY,
    trans_num VARCHAR(100),
    alert_type VARCHAR(50),
    alert_data JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    processed BOOLEAN DEFAULT FALSE
);
```

**Manual review:**

```sql
SELECT * FROM alert_queue WHERE NOT processed ORDER BY created_at DESC;
```

---

### **4. Custom Webhook** (Advanced)

G·ª≠i alert ƒë·∫øn internal service:

```yaml
ALERT_WEBHOOK=http://your-internal-service:8080/alerts
```

**Payload:**

```json
{
  "trans_num": "T123456",
  "amt": 1200.5,
  "risk_level": "HIGH",
  "fraud_probability": 0.952,
  "explanation": "...",
  "customer": "John Doe",
  "merchant": "Suspicious Shop"
}
```

---

## ‚úÖ Testing Alert Flow

### 1. Start services

```bash
docker-compose up -d spark-realtime-prediction alert-service
```

### 2. Insert test transaction (HIGH RISK)

```sql
INSERT INTO transactions (
    trans_date_trans_time, cc_num, merchant, category, amt,
    first, last, gender, street, city, state, zip,
    lat, long, city_pop, job, dob, trans_num, unix_time,
    merch_lat, merch_long, is_fraud
) VALUES (
    NOW(), 1234567890123456, 'Suspicious Shop', 'shopping_net', 1500.00,
    'John', 'Doe', 'M', '123 Main St', 'New York', 'NY', 10001,
    40.7128, -74.0060, 8000000, 'Engineer', '1990-01-01', 'TEST_001', EXTRACT(EPOCH FROM NOW()),
    35.0, -120.0,  -- 4000km away!
    1  -- Actual fraud
);
```

### 3. Check alerts

**Slack:** Check #fraud-alerts channel
**Email:** Check inbox
**Database:**

```sql
SELECT * FROM alert_queue ORDER BY created_at DESC LIMIT 1;
```

**Logs:**

```bash
docker logs spark-realtime-prediction --tail 50
docker logs alert-service --tail 50
```

### B∆∞·ªõc 1: T·∫°o App (T·ª´ m√†n h√¨nh b·∫°n ƒëang m·ªü)

**Trong h·ªôp tho·∫°i** **"Create an app"** **(nh∆∞ trong ·∫£nh 1 c·ªßa b·∫°n):**

- **Ch·ªçn** **From scratch** **(T√πy ch·ªçn d∆∞·ªõi c√πng).**
- **App Name**: ƒê·∫∑t t√™n cho bot, v√≠ d·ª•: **Fraud Alert Bot** **ho·∫∑c** **Fraud Detective**.
- **Pick a workspace to develop your app in**: Ch·ªçn Workspace Slack c·ªßa c√¥ng ty ho·∫∑c nh√≥m b·∫°n.
- **Nh·∫•n n√∫t** **Create App**.

### B∆∞·ªõc 2: B·∫≠t t√≠nh nƒÉng Webhook

**Sau khi t·∫°o xong, b·∫°n s·∫Ω ƒë∆∞·ª£c ƒë∆∞a v√†o trang qu·∫£n l√Ω App.**

- **Nh√¨n menu b√™n tay tr√°i, d∆∞·ªõi m·ª•c** **Features**, ch·ªçn **Incoming Webhooks**.
- **G·∫°t c√¥ng t·∫Øc** **Activate Incoming Webhooks** **sang** **On** **(M√†u xanh).**

### B∆∞·ªõc 3: T·∫°o Webhook URL cho k√™nh c·ª• th·ªÉ

- **K√©o xu·ªëng d∆∞·ªõi c√πng trang ƒë√≥, nh·∫•n v√†o n√∫t** **Add New Webhook to Workspace**.
- **Slack s·∫Ω h·ªèi b·∫°n mu·ªën post v√†o k√™nh n√†o.**

  - **Khuy√™n d√πng:** **B·∫°n n√™n t·∫°o m·ªôt k√™nh ri√™ng tr√™n Slack tr∆∞·ªõc (v√≠ d·ª•:** **#fraud-alerts**) ƒë·ªÉ kh√¥ng l√†m phi·ªÅn k√™nh chung.
  - **Ch·ªçn k√™nh ƒë√≥ trong danh s√°ch (v√≠ d·ª•:** **#general** **ho·∫∑c** **#fraud-alerts**).

- **Nh·∫•n** **Allow**.

### B∆∞·ªõc 4: L·∫•y URL v√† C·∫•u h√¨nh v√†o Project

**Sau khi nh·∫•n Allow, b·∫°n s·∫Ω th·∫•y m·ªôt d√≤ng** **Webhook URL** **m·ªõi hi·ªán ra, c√≥ d·∫°ng:**
https://hooks.slack.com/services/T000.../B000.../XXXX...

- **Copy** **ƒë∆∞·ªùng d·∫´n ƒë√≥.**
- **M·ªü file c·∫•u h√¨nh c·ªßa b·∫°n (th∆∞·ªùng l√†** **.env** **ho·∫∑c** **docker-compose.yml**) v√† d√°n v√†o bi·∫øn m√¥i tr∆∞·ªùng **SLACK_WEBHOOK_URL**.
