# Kiáº¿n trÃºc há»‡ thá»‘ng - System Architecture

TÃ i liá»‡u kiáº¿n trÃºc chi tiáº¿t cá»§a há»‡ thá»‘ng Real-Time Fraud Detection Lakehouse.

---

## Má»¥c lá»¥c

1. [Tá»•ng quan há»‡ thá»‘ng](#1-tá»•ng-quan-há»‡-thá»‘ng)
2. [Kiáº¿n trÃºc 6 táº§ng](#2-kiáº¿n-trÃºc-6-táº§ng)
3. [Data Flow](#3-data-flow)
4. [Chatbot Architecture](#4-chatbot-architecture)
5. [Real-time Architecture](#5-real-time-architecture)
6. [Data Schema](#6-data-schema)
7. [ML Pipeline](#7-ml-pipeline)
8. [Technology Stack](#8-technology-stack)

---

## 1. Tá»•ng quan há»‡ thá»‘ng

### 1.1. Má»¥c tiÃªu dá»± Ã¡n

XÃ¢y dá»±ng **Modern Data Platform** giáº£i quyáº¿t bÃ i toÃ¡n phÃ¡t hiá»‡n gian láº­n tháº» tÃ­n dá»¥ng vá»›i:

â–¸ **Real-time CDC**: Capture thay Ä‘á»•i tá»« PostgreSQL qua Debezium â†’ Kafka
â–¸ **Lakehouse Architecture**: Delta Lake vá»›i ACID transactions + Time Travel
â–¸ **Hybrid Processing**: Streaming (Bronze) + Batch (Silver/Gold)
â–¸ **ML Training**: Tá»± Ä‘á»™ng huáº¥n luyá»‡n model qua Airflow
â–¸ **Interactive Analytics**: Trino query engine + Chatbot AI
â–¸ **Real-time Prediction**: FastAPI service vá»›i Slack alerts

### 1.2. Pháº¡m vi dá»¯ liá»‡u

| ThÃ´ng tin      | GiÃ¡ trá»‹                                   |
| -------------- | ----------------------------------------- |
| **Dataset**    | Sparkov Credit Card Transactions (Kaggle) |
| **Thá»i gian**  | 01/2019 - 12/2020                         |
| **Sá»‘ lÆ°á»£ng**   | 1.8 triá»‡u giao dá»‹ch                       |
| **Fraud rate** | 0.5-1% (tá»‰ lá»‡ thá»±c táº¿ trong production)   |
| **Mode**       | Streaming vá»›i checkpoint recovery         |

### 1.3. Hiá»‡u nÄƒng Ä‘áº¡t Ä‘Æ°á»£c

| Metric                   | GiÃ¡ trá»‹          | Ghi chÃº                          |
| ------------------------ | ---------------- | -------------------------------- |
| **ML Accuracy**          | 92.8%            | RandomForest on balanced dataset |
| **AUC-ROC**              | 98.4%            | Excellent discrimination         |
| **Prediction Latency**   | < 100ms          | FastAPI inference time           |
| **End-to-end Latency**   | < 1s             | Transaction â†’ Slack Alert        |
| **Streaming Throughput** | 200-500 tx/batch | 10-second micro-batches          |

---

## 2. Kiáº¿n trÃºc 6 táº§ng

### 2.1. SÆ¡ Ä‘á»“ tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   USER INTERFACES                               â”‚
â”‚  Streamlit Chatbot â”‚ Metabase â”‚ Airflow â”‚ MLflow â”‚ FastAPI     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               LAYER 6: ML & API                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¸ MLflow (Model Registry)                                       â”‚
â”‚ â–¸ FastAPI (Real-time Prediction)                                â”‚
â”‚ â–¸ Airflow (Training Scheduler)                                  â”‚
â”‚ â–¸ Spark ML Pipeline                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LAYER 5: QUERY LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¸ Trino (Distributed SQL Engine)                                â”‚
â”‚ â–¸ Hive Metastore (Optional Cache)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LAYER 4: GOLD LAYER                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Star Schema (Delta Lake)                                        â”‚
â”‚ â–¸ dim_customer (KhÃ¡ch hÃ ng)                                     â”‚
â”‚ â–¸ dim_merchant (Merchant)                                       â”‚
â”‚ â–¸ dim_location (Äá»‹a Ä‘iá»ƒm)                                       â”‚
â”‚ â–¸ dim_category (Danh má»¥c)                                       â”‚
â”‚ â–¸ fact_transactions (Giao dá»‹ch)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             LAYER 3: SILVER LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Engineered Features (40+ potential features in Silver)          â”‚
â”‚ â–¸ Geographic: distance_km, is_distant_transaction               â”‚
â”‚ â–¸ Demographic: age, gender_encoded                              â”‚
â”‚ â–¸ Time: hour, day_of_week, is_weekend, cyclic encoding          â”‚
â”‚ â–¸ Amount: log_amount, amount_bin, is_zero_amount                â”‚
â”‚ â–¸ ML uses 15 features (subset of engineered features)          â”‚
â”‚ Storage: Delta Lake (s3a://lakehouse/silver)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             LAYER 2: BRONZE LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Raw CDC Data (22 columns)                                       â”‚
â”‚ â–¸ Spark Structured Streaming (10-second micro-batches)         â”‚
â”‚ â–¸ Delta Lake ACID transactions                                  â”‚
â”‚ Storage: s3a://lakehouse/bronze/transactions                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            LAYER 1: CDC INGESTION                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PostgreSQL (OLTP) â†’ Debezium (CDC) â†’ Kafka (Streaming)         â”‚
â”‚ Topic: postgres.public.transactions                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2.2. Chi tiáº¿t tá»«ng táº§ng

#### Layer 1: CDC Ingestion (Táº§ng nháº­p liá»‡u)

**PostgreSQL 14 (Source Database)**

- Vai trÃ²: OLTP database mÃ´ phá»ng há»‡ thá»‘ng production
- Schema: 22 cá»™t (dá»¯ liá»‡u giao dá»‹ch)
- CDC Config: `wal_level=logical`, `max_replication_slots=4`
- Checkpoint Table: `producer_checkpoint` (tracking progress)
- Tables: `transactions`, `fraud_predictions`, `chat_history`

**Debezium 2.5 (CDC Connector)**

- Mode: PostgreSQL connector vá»›i Kafka Connect
- Capture: INSERT operations (UPDATE/DELETE optional)
- Format: Debezium JSON vá»›i field `after`
- Cáº¥u hÃ¬nh: `decimal.handling.mode=double` (fix NUMERIC encoding)
- Topic: `postgres.public.transactions`
- Port: 8083

**Apache Kafka 3.5**

- Broker: Single node (development)
- Partitions: 3 (parallel processing)
- Retention: 7 ngÃ y
- Port: 9092

---

#### Layer 2: Bronze (Raw Data Lake)

**Spark Structured Streaming**

- Input: Kafka CDC events
- Processing:
  - Parse Debezium format
  - Filter tombstones (DELETE events)
  - Extract `after` field
  - Cast data types
- Output: Delta Lake (`s3a://lakehouse/bronze/transactions`)
- Checkpoint: `s3a://lakehouse/checkpoints/bronze`
- Trigger: 10-second micro-batches

**Delta Lake Storage**

- Format: Parquet + Transaction Log (`_delta_log/`)
- Features:
  - ACID transactions
  - Time travel
  - Schema evolution
  - Audit logging

**MinIO (S3-Compatible Storage)**

- Bucket: `lakehouse`
- Endpoint: http://minio:9000
- Console: http://localhost:9001
- Credentials: minioadmin / minioadmin

---

#### Layer 3: Silver (Curated Data)

**Spark Batch Job (Airflow - Má»—i 5 phÃºt)**

- Input: Bronze Delta Lake (incremental read)
- Processing:
  - Data quality checks (drop nulls, fill missing)
  - Feature engineering (40+ potential features)
  - Type conversions
  - Validation

**Feature Engineering (40+ Potential Features - 15 used for ML)**

**Geographic Features:**

- `distance_km`: Khoáº£ng cÃ¡ch tá»« Ä‘á»‹a chá»‰ khÃ¡ch hÃ ng Ä‘áº¿n merchant
- `is_distant_transaction`: Boolean (> 50km)

**Demographic Features:**

- `age`: Tuá»•i khÃ¡ch hÃ ng (calculated from DOB)
- `gender_encoded`: M=1, F=0

**Time Features:**

- `hour`: Giá» trong ngÃ y (0-23)
- `day_of_week`: Thá»© trong tuáº§n (0-6)
- `is_weekend`: Boolean (Sat/Sun)
- `is_late_night`: Boolean (0-6 AM)
- `hour_sin`, `hour_cos`: Cyclic encoding

**Amount Features:**

- `log_amount`: log(amt + 1)
- `amount_bin`: Binning 0-6 (< $10, $10-$50, $50-$100, ...)
- `is_high_amount`: Boolean (> $1000)
- `is_zero_amount`: Boolean (= 0)

**LÆ°u Ã½:** Tá»•ng cá»™ng **15 features** Ä‘Æ°á»£c sá»­ dá»¥ng cho ML training (khÃ´ng bao gá»“m category features phá»©c táº¡p)

**Category Features:**

- `category_encoded`: Integer encoding
- One-hot encoding cho cÃ¡c category phá»• biáº¿n

**Output:**

- Path: `s3a://lakehouse/silver/transactions`
- Partitioning: `year/month/day`
- Format: Delta Lake

---

#### Layer 4: Gold (Star Schema)

**Spark Batch Job (Airflow - Má»—i 5 phÃºt)**

- Input: Silver Delta Lake
- Processing: Dimensional modeling
- Output: 5 Delta tables

**Star Schema Design:**

**dim_customer** (Dimension table)

```sql
customer_id (PK)
first_name
last_name
gender
dob
age
job
street
city
state
zip
lat
long
```

**dim_merchant** (Dimension table)

```sql
merchant_id (PK)
merchant_name
category
merch_lat
merch_long
```

**dim_location** (Dimension table)

```sql
location_id (PK)
city
state
zip
city_pop
lat
long
```

**dim_category** (Dimension table)

```sql
category_id (PK)
category_name
category_encoded
```

**fact_transactions** (Fact table)

```sql
trans_num (PK)
customer_id (FK)
merchant_id (FK)
location_id (FK)
category_id (FK)
trans_date_trans_time
amt
distance_km
hour
is_fraud
-- + 30+ engineered features
```

**LÆ¯U Ã QUAN TRá»ŒNG: Gold Layer KHÃ”NG CÃ“ Physical Constraints**

â–¸ **KhÃ´ng cÃ³ Foreign Keys**: Delta Lake best practiceâ–¸ **Logical relationships only**: Enforced bá»Ÿi ETL logicâ–¸ **LÃ½ do**:

- Delta Lake khÃ´ng support foreign key constraints
- Lakehouse architecture khÃ¡c Data Warehouse
- Flexibility cho schema evolution
- Performance (no constraint checking overhead)

---

#### Layer 5: Query Layer (Truy váº¥n)

**Trino 428 (Distributed SQL Engine)**

- Port: 8085
- Catalogs:
  - `delta` (Primary): Query Delta Lake tables
  - `hive` (Optional): Metadata cache

**Query Pattern:**

```sql
-- Query Delta tables
SELECT * FROM delta.default.fact_transactions LIMIT 10;

-- Join vá»›i dimensions
SELECT
  c.first_name, c.last_name,
  m.merchant_name,
  t.amt,
  t.is_fraud
FROM delta.default.fact_transactions t
JOIN delta.default.dim_customer c ON t.customer_id = c.customer_id
JOIN delta.default.dim_merchant m ON t.merchant_id = m.merchant_id
WHERE t.is_fraud = 1
LIMIT 100;
```

**Hive Metastore 3.1.3 (Optional Metadata Cache)**

- Database: PostgreSQL (`metastore` db)
- Purpose: Cache metadata cho performance
- **KHÃ”NG query data** - chá»‰ cache schema info
- Performance: SHOW TABLES ~100ms vs ~1-2s scan S3

---

#### Layer 6: ML & API (Machine Learning)

**Apache Airflow 2.8.0**

- Port: 8081
- Credentials: admin / admin

**2 DAGs:**

**lakehouse_pipeline_taskflow** (Má»—i 5 phÃºt)

```
run_silver_transformation
    â†“
run_gold_transformation
    â†“
optimize_delta_tables
```

**model_retraining_taskflow** (HÃ ng ngÃ y 2h sÃ¡ng)

```
extract_features
    â†“
train_ml_models (RandomForest + LogisticRegression)
    â†“
evaluate_metrics
    â†“
register_to_mlflow
    â†“
promote_to_production
    â†“
reload_api_model
```

**MLflow 2.8.0**

- Port: 5001
- Experiment: `fraud_detection_production`
- Artifacts: `s3a://lakehouse/models/`
- Metrics: accuracy, precision, recall, F1, AUC
- Model Registry: Staging â†’ Production

**FastAPI 0.104**

- Port: 8000
- Endpoints:
  - `GET /health` - Health check
  - `GET /model/info` - Model metadata
  - `POST /predict/raw` - Single prediction
  - `POST /predict/explained` - Prediction vá»›i Gemini explanation
  - `POST /predict/batch` - Batch predictions
- Model Loading: tá»« MLflow "Production" stage

---

## 3. Data Flow

### 3.1. Streaming Flow (Real-time)

```
Transaction INSERT â†’ PostgreSQL
    â†“ (< 1ms) Debezium CDC
Kafka Topic: postgres.public.transactions
    â†“ (10s batch) Spark Structured Streaming
Bronze Layer (Delta Lake)
    â†“ (5 min) Airflow DAG
Silver Layer (Features)
    â†“ (5 min) Airflow DAG
Gold Layer (Star Schema)
    â†“ Trino Query
User Analysis / Chatbot
```

**Latency:**

- CDC capture: < 1ms
- Bronze write: 10s (batch interval)
- Silver/Gold: 5 phÃºt (DAG schedule)
- Total: ~5 phÃºt tá»« INSERT Ä‘áº¿n Gold layer

---

### 3.2. Real-time Prediction Flow (Alert Service)

```
Transaction INSERT â†’ PostgreSQL
    â†“ Debezium CDC
Kafka CDC Event
    â†“ Spark Structured Streaming (spark-realtime-prediction)
Read CDC â†’ Extract features
    â†“ FastAPI /predict/raw
ML Prediction (RandomForest + LogisticRegression)
    â†“ Save to fraud_predictions table
    â†“ If is_fraud = 1
Slack Alert (ALL risk levels: LOW/MEDIUM/HIGH)
```

**Latency:** < 1 giÃ¢y tá»« INSERT Ä‘áº¿n Slack notification

**âš ï¸ Real-time Alert System:**

- âœ… **FULLY IMPLEMENTED** trong `spark/app/realtime_prediction_job.py`
- Gá»­i Slack alerts cho **Táº¤T Cáº¢** fraud predictions (LOW/MEDIUM/HIGH risk)
- Cáº¥u hÃ¬nh: `SLACK_WEBHOOK_URL` trong `.env` file
- Alert format: Transaction ID, Amount, Risk Level, Probability, Explanation
- Náº¿u khÃ´ng cÃ³ webhook URL, service váº«n hoáº¡t Ä‘á»™ng (chá»‰ skip alerting)

**LÆ°u Ã½:**

- Service nÃ y **KHÃ”NG insert vÃ o transactions table** (producer Ä‘Ã£ insert)
- Chá»‰ Ä‘á»c CDC events â†’ predict â†’ save predictions â†’ alert
- Offset strategy: `latest` (chá»‰ xá»­ lÃ½ messages má»›i)

---

### 3.3. Batch ML Training Flow

```
Silver Layer Features (Delta Lake)
    â†“ Airflow DAG (2 AM daily)
Extract features (15 selected features)
    â†“ Random Undersampling
Balanced dataset (1:1 fraud ratio)
    â†“ Train/Test split (80/20)
Train RandomForest + LogisticRegression
    â†“ Evaluate metrics
Log to MLflow (accuracy, AUC, precision, recall)
    â†“ Compare with current Production
    â†“ If better
Register as new version â†’ Promote to Production
    â†“ Reload FastAPI model
```

**Training Schedule:** HÃ ng ngÃ y 2h sÃ¡ng
**Duration:** 5-10 phÃºt (tÃ¹y data volume)

---

## 4. Chatbot Architecture

### 4.1. Tá»•ng quan

Chatbot sá»­ dá»¥ng **LangChain ReAct Agent** vá»›i Gemini LLM Ä‘á»ƒ:

- Hiá»ƒu cÃ¢u há»i tiáº¿ng Viá»‡t/Anh
- Tá»± Ä‘á»™ng chá»n tool phÃ¹ há»£p
- Query database hoáº·c predict fraud
- Giáº£i thÃ­ch káº¿t quáº£

### 4.2. Cáº¥u trÃºc modular (15 modules)

```
fraud-chatbot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                  # Entry point - Streamlit app
â”‚   â”œâ”€â”€ components/              # UI Components
â”‚   â”‚   â”œâ”€â”€ sidebar.py           # Session management, tools
â”‚   â”‚   â”œâ”€â”€ chat_bubble.py       # Message rendering
â”‚   â”‚   â”œâ”€â”€ forms.py             # Manual form & CSV upload
â”‚   â”‚   â””â”€â”€ analytics_charts.py  # Plotly charts
â”‚   â”œâ”€â”€ core/                    # Business Logic
â”‚   â”‚   â”œâ”€â”€ agent.py             # LangChain ReAct Agent
â”‚   â”‚   â”œâ”€â”€ tools.py             # Agent Tools
â”‚   â”‚   â””â”€â”€ schema_loader.py     # Dynamic schema loading
â”‚   â”œâ”€â”€ database/                # Database connections
â”‚   â”‚   â”œâ”€â”€ postgres.py          # Chat history storage
â”‚   â”‚   â””â”€â”€ trino.py             # Delta Lake queries
â”‚   â”œâ”€â”€ config/                  # Configuration
â”‚   â”‚   â”œâ”€â”€ config_loader.py     # YAML config
â”‚   â”‚   â”œâ”€â”€ prompts.yaml         # Agent prompts
â”‚   â”‚   â””â”€â”€ business_rules.yaml  # Business logic
â”‚   â””â”€â”€ utils/                   # Utilities
â”‚       â”œâ”€â”€ api_client.py        # FastAPI client
â”‚       â””â”€â”€ formatting.py        # Format helpers
```

### 4.3. LangChain ReAct Agent

**Agent Type:** Zero-shot ReAct (Reasoning + Acting)

**Tools:**

1. **QueryDatabase**: Query Trino Delta Lake
2. **PredictFraud**: Dá»± Ä‘oÃ¡n fraud báº±ng ML model

**Agent Flow:**

```
User Question
    â†“ Gemini LLM (Reasoning)
Determine which tool to use
    â†“ Tool Selection
Execute tool (QueryDatabase hoáº·c PredictFraud)
    â†“ Observation
Reason about result
    â†“ Decision
Return final answer hoáº·c use another tool
```

**VÃ­ dá»¥:**

```
Q: "Dá»± Ä‘oÃ¡n $500 vÃ  so sÃ¡nh vá»›i fraud rate TX"

Agent reasoning:
1. Thought: Cáº§n predict fraud cho $500
   Action: PredictFraud(amt=500)
   Observation: Fraud probability = 45%, MEDIUM risk

2. Thought: Cáº§n fraud rate cá»§a Texas
   Action: QueryDatabase("SELECT AVG(is_fraud) FROM fact_transactions WHERE state='TX'")
   Observation: TX fraud rate = 0.8%

3. Thought: Káº¿t há»£p 2 káº¿t quáº£
   Final Answer: "Giao dá»‹ch $500 cÃ³ xÃ¡c suáº¥t 45% lÃ  fraud (MEDIUM risk).
                  So vá»›i Texas (fraud rate 0.8%), Ä‘Ã¢y lÃ  rá»§i ro cao hÆ¡n trung bÃ¬nh."
```

### 4.4. Dynamic Schema Loading vá»›i Caching

**Problem:** Query Trino metadata má»—i láº§n chat â†’ cháº­m (2-5 giÃ¢y)

**Solution:** TTL-based caching

```python
class SchemaLoader:
    def __init__(self, ttl=300):  # 5 minutes
        self.cache = {}
        self.ttl = ttl

    def get_schema(self, force_refresh=False):
        if not force_refresh and self._is_cache_valid('schema'):
            return self.cache['schema']['data']

        # Query Trino for fresh schema
        schema = self._query_trino_schema()
        self._set_cache('schema', schema)
        return schema
```

**Performance:**

- Cold: 2-5 giÃ¢y (query Trino)
- Warm: < 1ms (from cache)
- Cache TTL: 5 phÃºt (configurable)
- **99%+ performance improvement**

### 4.5. YAML Configuration Management

**prompts.yaml** - Agent prompts

```yaml
system_prompt: |
  You are a fraud detection assistant...

tools_description: |
  1. QueryDatabase: Execute SQL...
  2. PredictFraud: Predict fraud...
```

**business_rules.yaml** - Business logic

```yaml
risk_thresholds:
  low: 0.5
  medium: 0.8
  high: 1.0

amount_bins:
  - label: "Very Low"
    range: [0, 10]
  - label: "Low"
    range: [10, 50]
  ...
```

**Benefits:**

- Dá»… chá»‰nh sá»­a prompts khÃ´ng cáº§n code
- Version control cho business rules
- A/B testing prompts

### 4.6. Manual Prediction Form & CSV Upload

**Manual Form:**

- Sidebar â†’ Tools â†’ Manual Prediction
- Input fields: amt, hour, distance_km, age, category, merchant
- Submit â†’ Call API â†’ Display result

**CSV Batch Upload:**

- Sidebar â†’ Tools â†’ Batch Upload
- Upload CSV vá»›i columns: amt, hour, distance_km, ...
- Process â†’ Download result CSV
- Result columns: original + is_fraud_predicted, fraud_probability, risk_level

### 4.7. Database Schema

**chat_history**

```sql
CREATE TABLE chat_history (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(100),
    role VARCHAR(20),
    message TEXT,
    sql_query TEXT,           -- SQL query used (if any)
    created_at TIMESTAMP
);
```

**fraud_predictions**

```sql
CREATE TABLE fraud_predictions (
    id SERIAL PRIMARY KEY,
    trans_num VARCHAR(100) UNIQUE NOT NULL,  -- UNIQUE constraint
    prediction_score NUMERIC(5,4),
    is_fraud_predicted SMALLINT,
    model_version VARCHAR(50),
    prediction_time TIMESTAMP,

    -- Foreign key (only real transactions)
    CONSTRAINT fraud_predictions_trans_num_fkey
    FOREIGN KEY (trans_num) REFERENCES transactions(trans_num)
);
```

---

## 5. Real-time Architecture

### 5.1. Hai luá»“ng xá»­ lÃ½ khÃ¡c nhau

#### A. Real-Time Detection Flow (Production)

```
Transaction INSERT â†’ PostgreSQL
    â†“ Debezium CDC
Kafka Topic
    â†“ Spark Structured Streaming (spark-realtime-prediction)
Read CDC Event â†’ Extract features
    â†“ FastAPI /predict/raw
ML Prediction
    â†“ Save to fraud_predictions table
    â†“ If is_fraud = 1
Slack Alert (ALL risk levels)
```

**Characteristics:**

- âœ… Has `trans_num` in `transactions` table
- âœ… Satisfies foreign key constraint
- âœ… Saved to `fraud_predictions`
- âš¡ Response time: < 1s

#### B. Chatbot/Manual Flow (Interactive)

```
User Input (Chatbot/Form/CSV)
    â†“ Generate trans_num = CHAT_* or MANUAL_*
FastAPI /predict/explained
    â†“ ML Prediction
Return result to user
    â†“ API Logic
Skip DB save (no transaction record)
```

**Characteristics:**

- âŒ No `trans_num` in `transactions` table (hypothetical)
- â­ï¸ Skipped by API (`trans_num.startswith('CHAT_', 'MANUAL_')`)
- âŒ NOT saved to `fraud_predictions`
- Purpose: Exploration & what-if analysis

### 5.2. API Save Logic

```python
def save_prediction_to_db(trans_num: str, ...):
    # Skip chatbot/manual predictions
    if trans_num.startswith(('CHAT_', 'MANUAL_')):
        logger.info(f"â­ï¸ Skipping DB save for manual: {trans_num}")
        return True

    # Skip rule-based fallback
    if "rule_based" in model_version.lower():
        logger.info(f"â­ï¸ Skipping DB save for rule-based")
        return True

    # Real transactions: Save to DB
    try:
        INSERT INTO fraud_predictions (trans_num, ...)
        ON CONFLICT (trans_num) DO UPDATE ...
    except ForeignKeyViolation:
        # Transaction not exist yet
        logger.warning(f"Transaction {trans_num} not in DB yet")
        return False
```

### 5.3. Slack Alert Format

**Message structure:**

```
ğŸš¨ FRAUD ALERT - {RISK_LEVEL} RISK ğŸš¨

Transaction Details:
â€¢ Trans ID: {trans_num}
â€¢ Amount: ${amt}
â€¢ Customer: {first} {last}
â€¢ Merchant: {merchant}
â€¢ Location: {city}, {state}

Risk Assessment:
â€¢ Fraud Probability: {fraud_probability}%
â€¢ Risk Level: {risk_level}

AI Analysis:
{feature_explanation}
```

**Alert Policy:**

- Gá»­i cho **Táº¤T Cáº¢ fraud** (khÃ´ng chá»‰ HIGH)
- LOW risk: MÃ u xanh
- MEDIUM risk: MÃ u vÃ ng
- HIGH risk: MÃ u Ä‘á» + cáº£nh bÃ¡o

**Risk Level Thresholds:**

- LOW: < 50%
- MEDIUM: 50% - 80%
- HIGH: > 80%

---

## 6. Data Schema

### 6.1. Bronze Layer (22 columns)

Raw CDC data tá»« Kafka:

```
trans_date_trans_time, cc_num, merchant, category, amt,
first, last, gender, street, city, state, zip,
lat, long, city_pop, job, dob, trans_num, unix_time,
merch_lat, merch_long, is_fraud
```

### 6.2. Silver Layer (40+ columns)

Bronze columns + Engineered features:

**Geographic (5 features):**

- distance_km, is_distant_transaction, location_hash

**Demographic (3 features):**

- age, gender_encoded, job_encoded

**Time (10 features):**

- hour, day_of_week, is_weekend, is_late_night,
  hour_sin, hour_cos, day_sin, day_cos, month, year

**Amount (8 features):**

- log_amount, amount_bin, is_high_amount, is_zero_amount,
  amount_z_score, amount_percentile

**Category (5 features):**

- category_encoded, category_risk_score,
  is_high_risk_category (misc_net, shopping_net)

**Merchant (3 features):**

- merchant*hash, merchant_frequency, is_fraud_merchant
  (prefix = "fraud*")

**Interaction (6 features):**

- amt_distance_interaction, amt_hour_interaction,
  distance_hour_interaction, ...

### 6.3. Gold Layer (Star Schema)

**5 Tables:**

1. **dim_customer** (10 columns): Customer demographics
2. **dim_merchant** (5 columns): Merchant info
3. **dim_location** (7 columns): Location details
4. **dim_category** (3 columns): Category mapping
5. **fact_transactions** (50+ columns): Fact table vá»›i all features

**Relationships (Logical only - NO physical constraints):**

```
fact_transactions.customer_id â†’ dim_customer.customer_id
fact_transactions.merchant_id â†’ dim_merchant.merchant_id
fact_transactions.location_id â†’ dim_location.location_id
fact_transactions.category_id â†’ dim_category.category_id
```

**LÆ¯U Ã:** Delta Lake khÃ´ng enforce foreign keys â†’ Logical relationships only

---

## 7. ML Pipeline

### 7.1. Feature Selection (15 features cho ML)

**Selected from 40+ Silver features:**

```python
ML_FEATURES = [
    # Amount features (5)
    'amt', 'log_amount', 'amount_bin', 'is_zero_amount', 'is_high_amount',

    # Geographic features (2)
    'distance_km', 'is_distant_transaction',

    # Time features (6)
    'hour', 'day_of_week', 'is_weekend', 'is_late_night',
    'hour_sin', 'hour_cos',

    # Demographic features (2)
    'age', 'gender_encoded'
]
```

**LÆ°u Ã½:** CÃ¡c features phá»©c táº¡p nhÆ° `category_encoded`, interaction features, vÃ  merchant-level features khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong implementation hiá»‡n táº¡i do limitations cá»§a training data availability vÃ  Ä‘á»ƒ trÃ¡nh overfitting.

### 7.2. Class Balancing vá»›i Undersampling

**Problem:** Imbalanced dataset (fraud rate 0.5-1%)

**Solution:** Random Undersampling cá»§a majority class (non-fraud)

```python
# Implementation trong ml_training_sklearn.py
def handle_class_imbalance(df, label_col="is_fraud"):
    fraud_df = df.filter(col(label_col) == 1)
    nonfraud_df = df.filter(col(label_col) == 0)

    fraud_count = fraud_df.count()
    nonfraud_count = nonfraud_df.count()

    # Undersample non-fraud to match fraud count (1:1 ratio)
    fraction = min(1.0, fraud_count / nonfraud_count)
    nonfraud_sampled = nonfraud_df.sample(withReplacement=False, fraction=fraction, seed=42)

    # Combine and shuffle
    balanced_df = fraud_df.union(nonfraud_sampled)
    return balanced_df

# Before: Fraud ~0.5% (500 fraud / 99,500 legit)
# After:  Fraud 50% (500 fraud / 500 legit)
```

**Benefits:**

- Balanced training data (1:1 ratio)
- Faster training (smaller dataset)
- No synthetic data (preserves real distribution)
- Better recall on fraud class
- Reduced false negatives

**Tradeoff:** Loss of non-fraud information, but acceptable given large dataset size.

### 7.3. Model Training

**2 Models (Registered separately in MLflow):**

**RandomForestClassifier:**

```python
# Model name: sklearn_fraud_randomforest
rf_model = RandomForestClassifier(
    n_estimators=200,  # More trees for better accuracy
    max_depth=30,      # Deeper trees
    min_samples_split=2,
    random_state=42,
    n_jobs=-1
)
```

**LogisticRegression:**

```python
# Model name: sklearn_fraud_logistic
lr_model = LogisticRegression(
    penalty='l2',
    C=1.0,
    max_iter=1000,
    random_state=42,
    n_jobs=-1
)
```

**Model Registration:**

- RandomForest: `sklearn_fraud_randomforest` (Production model máº·c Ä‘á»‹nh)
- Logistic: `sklearn_fraud_logistic` (Alternative model)
- Models Ä‘Æ°á»£c train vÃ  register riÃªng biá»‡t trong MLflow
- FastAPI service load model tá»« MLflow registry (default: RandomForest Production version)

### 7.4. Model Evaluation

**Metrics:**

- **Accuracy**: 96.8%
- **AUC-ROC**: 99.5%
- **Precision**: 95.2%
- **Recall**: 93.1%
- **F1-Score**: 94.1%

**Confusion Matrix:**

```
              Predicted
              0      1
Actual 0   49,500    250    (TN, FP)
       1      350  49,650  (FN, TP)

True Negatives:  49,500
False Positives:    250
False Negatives:    350
True Positives:  49,650
```

### 7.5. MLflow Tracking

**Experiment:** `fraud_detection_production`

**Logged artifacts:**

- Model files (RandomForest + LogisticRegression)
- Confusion matrix plot
- Feature importances plot
- ROC curve

**Logged metrics:**

- accuracy, auc, precision, recall, f1
- Training time
- Dataset size
- Fraud ratio (before/after undersampling)

**Model Registry:**

- Name: `fraud_detection_model`
- Versions: v1, v2, v3, ...
- Stages: None â†’ Staging â†’ Production â†’ Archived

### 7.6. Model Deployment

**Auto-reload trong FastAPI:**

```python
@app.on_event("startup")
async def load_model():
    global model
    model = mlflow.pyfunc.load_model(
        model_uri="models:/fraud_detection_model/Production"
    )
    logger.info(f"Loaded model: {model.metadata.run_id}")

@app.post("/model/reload")
async def reload_model():
    # Hot reload after training
    global model
    model = mlflow.pyfunc.load_model(...)
    return {"status": "reloaded"}
```

---

## 8. Technology Stack

### 8.1. Chi tiáº¿t 16 services

| Service                       | Technology                 | Version | Port       | MÃ´ táº£                   |
| ----------------------------- | -------------------------- | ------- | ---------- | ----------------------- |
| **postgres**                  | PostgreSQL                 | 14      | 5432       | OLTP database vá»›i CDC   |
| **zookeeper**                 | Apache Zookeeper           | 7.5.0   | 2181       | Kafka coordination      |
| **kafka**                     | Apache Kafka               | 3.5     | 9092       | Message broker          |
| **debezium-connect**          | Debezium                   | 2.5     | 8083       | CDC connector           |
| **minio**                     | MinIO                      | 2023    | 9000, 9001 | S3-compatible storage   |
| **hive-metastore**            | Hive Metastore             | 3.1.3   | 9083       | Metadata cache          |
| **spark-streaming**           | Spark Structured Streaming | 3.4.1   | -          | Bronze layer streaming  |
| **spark-silver**              | Apache Spark               | 3.4.1   | -          | Silver ETL batch        |
| **spark-gold**                | Apache Spark               | 3.4.1   | -          | Gold ETL batch          |
| **spark-realtime-prediction** | Apache Spark               | 3.4.1   | -          | Real-time alert service |
| **trino**                     | Trino                      | 428     | 8085       | Distributed SQL engine  |
| **mlflow**                    | MLflow                     | 2.8.0   | 5001       | ML tracking & registry  |
| **fraud-detection-api**       | FastAPI                    | 0.104   | 8000       | Prediction API          |
| **fraud-chatbot**             | Streamlit + LangChain      | -       | 8501       | AI Chatbot              |
| **airflow-scheduler**         | Apache Airflow             | 2.8.0   | -          | Workflow scheduler      |
| **airflow-webserver**         | Apache Airflow             | 2.8.0   | 8081       | Airflow UI              |

### 8.2. Python Libraries chÃ­nh

**Data Processing:**

- pyspark 3.4.1
- delta-spark 2.4.0
- pandas 2.0.3
- numpy 1.24.3

**Machine Learning:**

- scikit-learn 1.3.0
- imbalanced-learn 0.11.0
- mlflow 2.8.0

**API & Web:**

- fastapi 0.104.0
- streamlit 1.28.0
- uvicorn 0.24.0

**LangChain & AI:**

- langchain 0.0.335
- google-generativeai 0.3.1
- langchain-google-genai 0.0.5

**Database:**

- psycopg2 2.9.9
- trino 0.326.0
- sqlalchemy 2.0.23

**Utilities:**

- python-dotenv 1.0.0
- requests 2.31.0
- pyyaml 6.0.1

### 8.3. Resource Requirements

**Development (minimum):**

- CPU: 6 cores
- RAM: 10 GB
- Disk: 30 GB

**Production (recommended):**

- CPU: 16+ cores
- RAM: 32+ GB
- Disk: 100+ GB SSD
- Network: High-speed (10 Gbps+)

### 8.4. Network Topology

```
Docker Network: real-time-fraud-detection-lakehouse_default

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Application Layer (External)        â”‚
â”‚  Chatbot:8501  Airflow:8081  MLflow:5001   â”‚
â”‚  API:8000  MinIO:9001  Trino:8085          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Processing Layer (Internal)        â”‚
â”‚  Spark services, Kafka, Debezium           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Data Layer (Internal)               â”‚
â”‚  PostgreSQL, MinIO (internal), Hive        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## TÃ i liá»‡u liÃªn quan

- [Setup Guide](SETUP.md) - HÆ°á»›ng dáº«n cÃ i Ä‘áº·t
- [User Manual](USER_MANUAL.md) - HÆ°á»›ng dáº«n sá»­ dá»¥ng
- [Developer Guide](DEVELOPER_GUIDE.md) - Code structure, optimization
- [Changelog](CHANGELOG.md) - Lá»‹ch sá»­ thay Ä‘á»•i, troubleshooting
