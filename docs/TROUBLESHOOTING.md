# Troubleshooting Guide - Hive Metastore & Trino Integration

> **TÃ i liá»‡u nÃ y ghi láº¡i cÃ¡c váº¥n Ä‘á» gáº·p pháº£i vÃ  giáº£i phÃ¡p khi setup Trino + Hive Metastore cho Data Lakehouse**

---

## ğŸ“‹ Tá»•ng Quan

### Má»¥c TiÃªu

Setup Trino Ä‘á»ƒ Metabase cÃ³ thá»ƒ query Delta Lake tables. **Hive Metastore lÃ  metadata cache (optional)**.

### âš ï¸ LÆ¯U Ã QUAN TRá»ŒNG

- **Hive Metastore**: CHá»ˆ lÃ  metadata cache (giÃºp `SHOW TABLES` nhanh)
- **Delta catalog**: PHáº¢I dÃ¹ng Ä‘á»ƒ query data (`delta.bronze.*`, `delta.silver.*`, `delta.gold.*`)
- **Hive catalog**: CHá»ˆ list tables, KHÃ”NG query Ä‘Æ°á»£c Delta format

### Kiáº¿n TrÃºc Cuá»‘i CÃ¹ng

```
Metabase (Visualization)
    â†“ SQL Queries (jdbc:trino://trino:8081/delta)
Trino (Query Engine - port 8081)
    â”œâ”€â†’ Delta Catalog (Query data: Ä‘á»c _delta_log/ + S3)
    â””â”€â†’ Hive Catalog (List metadata: SHOW TABLES nhanh)
            â†“
Hive Metastore (Metadata Cache - port 9083) â† OPTIONAL!
    â†“ PostgreSQL
metastore-db (Schema info)

MinIO (Object Storage - port 9000)
    â””â”€â”€ Delta Lake Files (_delta_log/ + Parquet)
        â”œâ”€â”€ bronze/
        â”œâ”€â”€ silver/
        â””â”€â”€ gold/
```

---

## âš ï¸ Váº¥n Äá» #1: Hive Metastore Schema Conflicts

### Triá»‡u Chá»©ng

```
ERROR: relation "BUCKETING_COLS" already exists
FATAL: database system is corrupted
```

Má»—i láº§n restart container, Hive Metastore crash do conflict schema trong PostgreSQL.

### NguyÃªn NhÃ¢n

- **Volume persistence**: PostgreSQL data Ä‘Æ°á»£c persist qua `metastore_db` volume
- Khi Hive Metastore restart â†’ cá»‘ init schema láº¡i â†’ schema Ä‘Ã£ tá»“n táº¡i â†’ crash
- `initSchema=true` + existing schema = conflict

### Giáº£i PhÃ¡p âœ…

**XÃ³a volume persistence** trong `docker-compose.yml`:

```yaml
# âŒ CÅ¨ (gÃ¢y lá»—i):
metastore-db:
  image: postgres:14
  volumes:
    - metastore_db:/var/lib/postgresql/data # â† XÃ“A DÃ’NG NÃ€Y

volumes:
  metastore_db: # â† XÃ“A VOLUME DEFINITION
```

```yaml
# âœ… Má»šI (hoáº¡t Ä‘á»™ng):
metastore-db:
  image: postgres:14
  # KhÃ´ng cÃ³ volumes - fresh DB má»—i láº§n start
  environment:
    POSTGRES_DB: metastore
    POSTGRES_USER: hive
    POSTGRES_PASSWORD: hive123
```

**Káº¿t Quáº£:**

- Fresh PostgreSQL DB má»—i láº§n restart
- Hive Metastore auto-init schema thÃ nh cÃ´ng
- KhÃ´ng cÃ²n conflict errors
- Tables Ä‘Æ°á»£c re-register tá»± Ä‘á»™ng qua `hive-registration` service

---

## âš ï¸ Váº¥n Äá» #2: Hadoop Version Mismatch

### Triá»‡u Chá»©ng

```
java.lang.ClassNotFoundException: org.apache.hadoop.fs.s3a.S3AFileSystem
java.lang.NoSuchMethodError: org.apache.hadoop.fs.statistics.IOStatisticsSource.getIOStatistics()
```

### NguyÃªn NhÃ¢n

- **Hive 3.1.3** sá»­ dá»¥ng **Hadoop 3.1.0** internally
- Custom JARs dÃ¹ng **Hadoop 3.3.4** â†’ version conflict
- Methods khÃ´ng tÆ°Æ¡ng thÃ­ch giá»¯a Hadoop 3.1.0 vs 3.3.4

### Giáº£i PhÃ¡p âœ…

**Downgrade vá» Hadoop 3.1.0 compatible JARs:**

```bash
# deployment/hive-metastore/lib/
hadoop-aws-3.1.0.jar              # â† Tá»« 3.3.4 â†’ 3.1.0
aws-java-sdk-bundle-1.11.375.jar  # â† Tá»« 1.12.262 â†’ 1.11.375

# XÃ“A cÃ¡c JARs gÃ¢y conflict:
# hadoop-common-3.3.4.jar         # â† XÃ“A
# hadoop-shaded-guava-*.jar       # â† XÃ“A
```

**Dockerfile update:**

```dockerfile
FROM apache/hive:3.1.3

# Copy JARs vÃ o Cáº¢ 2 locations Ä‘á»ƒ cháº¯c cháº¯n
COPY lib/*.jar /opt/hive/lib/
COPY lib/*.jar /opt/hadoop/share/hadoop/common/lib/

# Copy S3A configuration
COPY core-site.xml /opt/hadoop/etc/hadoop/core-site.xml
```

**Káº¿t Quáº£:**

- KhÃ´ng cÃ²n ClassNotFoundException
- S3AFileSystem load thÃ nh cÃ´ng
- Compatible vá»›i Hive 3.1.3

---

## âš ï¸ Váº¥n Äá» #3: MinIO Credential Mismatch

### Triá»‡u Chá»©ng

```
Status Code: 403, AWS Service: Amazon S3, AWS Request ID: null
AWS Error Code: null, AWS Error Message: Forbidden
```

### NguyÃªn NhÃ¢n

- MinIO service dÃ¹ng credentials: `minio` / `minio123`
- Hive Metastore config dÃ¹ng credentials: `minioadmin` / `minioadmin`
- â†’ 403 Forbidden khi access S3

### Giáº£i PhÃ¡p âœ…

**Update `core-site.xml`:**

```xml
<!-- deployment/hive-metastore/core-site.xml -->
<configuration>
  <property>
    <name>fs.s3a.impl</name>
    <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
  </property>

  <property>
    <name>fs.s3a.access.key</name>
    <value>minio</value>  <!-- â† Tá»« minioadmin â†’ minio -->
  </property>

  <property>
    <name>fs.s3a.secret.key</name>
    <value>minio123</value>  <!-- â† Tá»« minioadmin â†’ minio123 -->
  </property>

  <property>
    <name>fs.s3a.endpoint</name>
    <value>http://minio:9000</value>
  </property>

  <property>
    <name>fs.s3a.path.style.access</name>
    <value>true</value>
  </property>

  <property>
    <name>fs.s3a.connection.ssl.enabled</name>
    <value>false</value>
  </property>
</configuration>
```

**Káº¿t Quáº£:**

- Hive Metastore connect MinIO thÃ nh cÃ´ng
- `CREATE SCHEMA` vÃ  `CREATE TABLE` hoáº¡t Ä‘á»™ng
- Trino query Delta Lake qua Hive Metastore

---

## âš ï¸ Váº¥n Äá» #4: MSCK REPAIR TABLE Incompatible

### Triá»‡u Chá»©ng

```
ERROR: Failed to register bronze.transactions: MSCK REPAIR TABLE is not supported for v2 tables
ERROR: Failed to register gold.dim_customer: MSCK REPAIR TABLE is not supported for v2 tables
```

Chá»‰ 2/7 tables Ä‘Æ°á»£c register thÃ nh cÃ´ng (dim_location, fact_transactions).

### NguyÃªn NhÃ¢n

- **Delta Lake v2** sá»­ dá»¥ng format má»›i vá»›i transaction log (`_delta_log/`)
- `MSCK REPAIR TABLE` lÃ  Hive command cho format cÅ© (Parquet partitioned)
- Delta Lake tá»± Ä‘á»™ng quáº£n lÃ½ partitions â†’ khÃ´ng cáº§n MSCK

### Giáº£i PhÃ¡p âœ…

**XÃ³a MSCK REPAIR command** trong `register_tables_to_hive.py`:

```python
# âŒ CÅ¨ (line 63):
spark.sql(f"MSCK REPAIR TABLE {database}.{table_name}")

# âœ… Má»šI (line 63-64):
# Note: MSCK REPAIR TABLE not supported for Delta v2 tables
# Delta automatically manages partitions
```

**LÃ½ Do:**

- Delta Lake tá»± Ä‘á»™ng update partition metadata trong `_delta_log/`
- Trino Ä‘á»c metadata trá»±c tiáº¿p tá»« Delta transaction log
- CREATE EXTERNAL TABLE Ä‘Ã£ Ä‘á»§ Ä‘á»ƒ register

**Káº¿t Quáº£:**

- âœ… 7/7 tables registered thÃ nh cÃ´ng
- âœ… Bronze: transactions (25K records)
- âœ… Silver: transactions (25K records)
- âœ… Gold: dim_customer, dim_merchant, dim_time, dim_location, fact_transactions

---

## âš ï¸ Váº¥n Äá» #5: Hive Metastore Connection Refused

### Triá»‡u Chá»©ng

```
org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
WARN metastore: Failed to connect to the MetaStore Server...
```

### NguyÃªn NhÃ¢n

- Spark job start quÃ¡ nhanh trÆ°á»›c khi Hive Metastore ready
- Thrift server chÆ°a listen trÃªn port 9083

### Giáº£i PhÃ¡p âœ…

**ThÃªm retry logic vÃ  wait** trong registration service:

```python
# spark/app/register_tables_to_hive.py
import time

def wait_for_hive_metastore(max_retries=20, retry_interval=5):
    """Wait for Hive Metastore to be ready"""
    for attempt in range(max_retries):
        try:
            spark = create_spark_session()
            # Test connection
            spark.sql("SHOW DATABASES").collect()
            logger.info("âœ… Hive Metastore is ready!")
            return spark
        except Exception as e:
            if attempt < max_retries - 1:
                logger.warning(f"Attempt {attempt+1}/{max_retries} - Hive Metastore not ready, retrying...")
                time.sleep(retry_interval)
            else:
                raise
```

**Docker depends_on:**

```yaml
# docker-compose.yml
hive-registration:
  depends_on:
    - hive-metastore
    - spark-master
  # Wait for Hive Metastore to initialize
```

**Káº¿t Quáº£:**

- Registration job Ä‘á»£i Metastore ready
- KhÃ´ng cÃ²n connection refused errors
- Auto-retry thÃ nh cÃ´ng sau 10-15 giÃ¢y

---

## âš ï¸ Váº¥n Äá» #6: Trino Port Confusion

### Triá»‡u Chá»©ng

```
java.net.ConnectException: Failed to connect to localhost/[0:0:0:0:0:0:0:1]:8080
```

Metabase khÃ´ng connect Ä‘Æ°á»£c Trino.

### NguyÃªn NhÃ¢n

- Trino internal port: **8081** (HTTP coordinator)
- Trino external port: **8085** (mapped to host)
- Default `trino` CLI tool dÃ¹ng port 8080 â†’ sai

### Giáº£i PhÃ¡p âœ…

**Sá»­ dá»¥ng Ä‘Ãºng port:**

```bash
# âœ… Inside Docker network:
docker exec trino trino --server localhost:8081 --execute "SHOW TABLES FROM delta.gold"

# âœ… From host machine:
trino --server localhost:8085 --execute "SHOW TABLES FROM delta.gold"
```

**Metabase configuration:**

```yaml
Database Type: Trino
Host: trino # â† Docker service name
Port: 8081 # â† Internal port
Catalog: delta
Database: gold
```

**Náº¿u Metabase cháº¡y ngoÃ i Docker:**

```yaml
Host: localhost
Port: 8085 # â† External mapped port
```

**Káº¿t Quáº£:**

- Metabase connect Trino thÃ nh cÃ´ng
- Query all 7 tables tá»« bronze/silver/gold
- Dashboards hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng

---

## ğŸ“Š Verification Checklist

### 1. Hive Metastore Health

```bash
docker logs hive-metastore --tail 30

# âœ… Mong Ä‘á»£i:
# Starting Hive Metastore Server
# Metastore connection URL: jdbc:postgresql://metastore-db:5432/metastore
# Starting hive metastore on port 9083
```

### 2. Hive Registration Status

```bash
docker logs hive-registration --tail 50

# âœ… Mong Ä‘á»£i:
# âœ… Registered bronze.transactions (25,000 records)
# âœ… Registered silver.transactions (25,000 records)
# âœ… Registered gold.dim_customer
# âœ… Registered gold.dim_merchant
# âœ… Registered gold.dim_time
# âœ… Registered gold.dim_location
# âœ… Registered gold.fact_transactions (25,000 records)
# âœ… Registration completed successfully!
```

### 3. Trino Connectivity

```bash
# Test Trino CLI
docker exec trino trino --server localhost:8081 --execute "SHOW CATALOGS"

# âœ… Mong Ä‘á»£i:
# "delta"
# "hive"
# "system"

# Test schemas
docker exec trino trino --server localhost:8081 --execute "SHOW SCHEMAS FROM delta"

# âœ… Mong Ä‘á»£i:
# "bronze"
# "silver"
# "gold"
# "information_schema"

# Test tables
docker exec trino trino --server localhost:8081 --execute "SHOW TABLES FROM delta.gold"

# âœ… Mong Ä‘á»£i:
# "dim_customer"
# "dim_location"
# "dim_merchant"
# "dim_time"
# "fact_transactions"
```

### 4. Query Sample Data

```bash
docker exec trino trino --server localhost:8081 --execute "
SELECT
    'bronze.transactions' as table_name,
    COUNT(*) as records
FROM delta.bronze.transactions
UNION ALL
SELECT
    'silver.transactions',
    COUNT(*)
FROM delta.silver.transactions
UNION ALL
SELECT
    'gold.fact_transactions',
    COUNT(*)
FROM delta.gold.fact_transactions
"

# âœ… Mong Ä‘á»£i:
# "bronze.transactions","25000"
# "silver.transactions","25000"
# "gold.fact_transactions","25000"
```

---

## ğŸ”§ Final Working Configuration

### Hive Metastore

- **Image**: Custom from `apache/hive:3.1.3`
- **JARs**: Hadoop 3.1.0 + AWS SDK 1.11.375
- **Database**: PostgreSQL (no persistence)
- **Port**: 9083 (Thrift)
- **Config**: `core-site.xml` with S3A settings

### Trino

- **Image**: `trinodb/trino:latest`
- **Catalogs**:
  - `delta` (Delta Lake via Hive Metastore)
  - `hive` (backup option)
- **Ports**:
  - Internal: 8081
  - External: 8085

### Registration Service

- **Script**: `spark/app/register_tables_to_hive.py`
- **Schedule**: Every 1 hour
- **Tables**: 7 tables (1 bronze + 1 silver + 5 gold)
- **Mode**: PySpark with Hive support

### MinIO

- **Credentials**: `minio` / `minio123`
- **Endpoint**: `http://minio:9000`
- **Bucket**: `lakehouse`
- **Structure**: `/bronze/`, `/silver/`, `/gold/`

---

## ğŸ¯ Key Learnings

### 1. Volume Persistence

âŒ **KhÃ´ng nÃªn** persist Metastore DB khi dÃ¹ng `initSchema=true`  
âœ… **NÃªn** Ä‘á»ƒ fresh DB + auto re-register tables

### 2. Version Compatibility

âŒ Hive 3.1.3 + Hadoop 3.3.4 = NoSuchMethodError  
âœ… Hive 3.1.3 + Hadoop 3.1.0 = Compatible

### 3. Delta Lake Format

âŒ MSCK REPAIR TABLE cho Delta v2 = Not supported  
âœ… CREATE EXTERNAL TABLE USING DELTA = Äá»§ rá»“i

### 4. Credential Consistency

âŒ MinIO credentials khÃ¡c core-site.xml = 403 Forbidden  
âœ… Credentials match everywhere = Success

### 5. Port Configuration

âŒ Trino default port 8080 = Connection refused  
âœ… Trino actual port 8081 (internal) / 8085 (external) = Working

---

## âš ï¸ Váº¥n Äá» #7: ML Training vá»›i Ã­t samples (~15-20)

### Triá»‡u Chá»©ng

MLflow UI hiá»ƒn thá»‹:

- `train_samples: 14-17`
- `test_samples: 3-4`
- Tá»•ng chá»‰ ~20 samples

User cÃ³ 4000+ records trong Silver layer nhÆ°ng ML chá»‰ train vá»›i ~20 samples.

### NguyÃªn NhÃ¢n

**ÄÃ‚Y KHÃ”NG PHáº¢I Lá»–I - ÄÃ¢y lÃ  real-world fraud detection behavior!**

| Metric                    | Value           | Explanation                       |
| ------------------------- | --------------- | --------------------------------- |
| Total records (Silver)    | ~4,200          | Sau vÃ i phÃºt streaming            |
| **Fraud transactions**    | ~10 (0.24%)     | **Real-world fraud rate: 0.5-1%** |
| Non-fraud transactions    | ~4,190 (99.76%) | Majority class                    |
| **After class balancing** |                 |                                   |
| Fraud (keep all)          | 10              | Minority class - giá»¯ nguyÃªn       |
| Non-fraud (undersampled)  | 10              | Undersampling Ä‘á»ƒ balance 1:1      |
| **Total balanced**        | 20              | Training dataset                  |
| Train set (80%)           | ~16             |                                   |
| Test set (20%)            | ~4              |                                   |

**LÃ½ do:**

1. âœ… **Fraud imbalance**: Real-world fraud rate ráº¥t tháº¥p (0.5-1%)
2. âœ… **Class balancing**: ML job undersample majority class Ä‘á»ƒ trÃ¡nh bias
3. âœ… **Early stage**: Data producer má»›i cháº¡y vÃ i phÃºt â†’ Ã­t fraud samples
4. â° **Cáº§n thá»i gian**: Äá»£i 2-4 giá» Ä‘á»ƒ cÃ³ ~50-100 fraud samples â†’ training tá»‘t hÆ¡n

### Giáº£i PhÃ¡p âœ…

**Option 1: Bulk Load Initial Data (Recommended)**

```powershell
# Load 50K transactions ngay láº­p tá»©c (~250 fraud samples)
docker exec data-producer python producer.py --bulk-load 50000

# Káº¿t quáº£:
# - ~50K records loaded trong 2-3 phÃºt
# - ~250 fraud transactions (0.5% fraud rate)
# - Äá»§ data cho ML training ngay
# - Sau Ä‘Ã³ tiáº¿p tá»¥c streaming bÃ¬nh thÆ°á»ng
```

**CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:**

1. âœ… Bulk load â†’ Insert nhanh 50K records vÃ o PostgreSQL
2. âœ… Debezium CDC â†’ Capture INSERT events â†’ Kafka
3. âœ… Bronze streaming â†’ Xá»­ lÃ½ CDC events â†’ Delta Lake
4. âœ… Silver/Gold batch â†’ Cháº¡y 5 phÃºt sau â†’ Ready for training
5. âœ… Data producer â†’ Tiáº¿p tá»¥c streaming vá»›i records cÃ²n láº¡i

**Checkpoint safe:**

- âœ… PostgreSQL SERIAL primary key â†’ KhÃ´ng duplicate
- âœ… Debezium LSN (Log Sequence Number) â†’ Resume tá»« Ä‘Ãºng vá»‹ trÃ­
- âœ… Spark streaming checkpoint â†’ Exactly-once semantics

**Option 2: TÄƒng tá»‘c streaming**

```python
# Modify services/data-producer/producer.py
# Line ~35: Giáº£m sleep time
time.sleep(0.5)  # Thay vÃ¬ time.sleep(5)

# Restart
docker compose restart data-producer
```

**Option 3: Äá»£i tá»± nhiÃªn**

- Chá» 2-4 giá» Ä‘á»ƒ data producer insert Ä‘á»§ data
- Fraud rate 0.5% â†’ 100 frauds cáº§n ~20K transactions
- Schedule: Daily 2 AM training (tá»± Ä‘á»™ng qua Airflow)

### Khi nÃ o nÃªn re-train?

- âœ… Sau khi cÃ³ **â‰¥100 fraud samples** (better accuracy)
- âœ… Schedule: Daily 2 AM (tá»± Ä‘á»™ng qua Airflow)
- âœ… Manual trigger: Airflow UI â†’ model_retraining_taskflow â†’ â–¶ï¸

### Verify data distribution

```sql
-- Check fraud distribution
docker exec trino trino --server localhost:8081 --execute \
  "SELECT is_fraud, COUNT(*) as count FROM delta.silver.transactions GROUP BY is_fraud"

-- Expected output (early stage):
-- "0","4190"   -- Non-fraud
-- "1","10"     -- Fraud (0.24%)

-- Expected output (after bulk load 50K):
-- "0","49750"  -- Non-fraud
-- "1","250"    -- Fraud (0.5%)
```

---

## ğŸ“– Related Documentation

- **Metabase Setup**: [`docs/METABASE_SETUP.md`](./METABASE_SETUP.md) - Connection settings & sample queries
- **Project Spec**: [`docs/PROJECT_SPECIFICATION.md`](./PROJECT_SPECIFICATION.md) - Full architecture details
- **Hive Metastore Role**: [`docs/HIVE_METASTORE_ROLE.md`](./HIVE_METASTORE_ROLE.md) - Metadata cache vs query engine

---

## ğŸ’¡ Quick Fixes

### Reset Everything

```bash
# Stop all services
docker-compose down

# Remove volumes (optional - only if needed)
docker volume prune -f

# Restart fresh
docker-compose up -d

# Wait 2-3 minutes for registration
docker logs -f hive-registration
```

### Force Re-registration

```bash
# Restart registration service
docker-compose restart hive-registration

# Watch logs
docker logs -f hive-registration
```

### Check Service Health

```bash
# All services status
docker-compose ps

# CPU/Memory usage
docker stats --no-stream

# Specific service logs
docker logs <service-name> --tail 50
```

---

## âœ… Success Indicators

Khi má»i thá»© hoáº¡t Ä‘á»™ng Ä‘Ãºng, báº¡n sáº½ tháº¥y:

1. âœ… Hive Metastore running without errors
2. âœ… Hive registration completes with 7/7 tables
3. âœ… Trino SHOW CATALOGS returns `delta` and `hive`
4. âœ… Trino SHOW SCHEMAS returns `bronze`, `silver`, `gold`
5. âœ… Trino SHOW TABLES returns all 7 tables
6. âœ… Trino SELECT queries return data
7. âœ… Metabase connects and shows all tables
8. âœ… No 403 Forbidden errors in logs
9. âœ… No ClassNotFoundException errors
10. âœ… No MSCK REPAIR errors

**Total time from start to fully operational: ~5 minutes**

---

**Last Updated**: December 2, 2025  
**Status**: âœ… All issues resolved, system operational
